---
title: "A Lexicon of Distributional Regression Models"
format:
  html: default 
  pdf: default 
number-sections: false   
number-depth: 4
editor: visual
quarto: add leovan/quarto-pseudocode
author: GAMLSS working party  
bibliography: book2026.bib  
---

## Introduction

This is a lexicon of terms and ideas related to statistical modelling in general but more specifically to [distributional regression] models. The lexicon started on ideas presented in the talk [Regression Models; how to adapt for climate change challenges](https://mstasinopoulos.github.io/Brazil2025-talk/talk_2.html#/title-slide) given by Mikis Stasinopoulos, University of Greenwich, to the XVII Encontro Mineiro de Statistica on Octomber 2025, in Lavras, Brazil. It was soon realised that there is also a gap between the [statistical modelling] terminology and the terminology used by other data analysis scientists. For example, the [response] variable a well known expression to describe the variable of interest in a [regression analysis] it is called the [target] in [machine learning]. Similarly the [explanatory variables] are refer to as [feature]s. The present lexicon is trying to close this gap by describing both definitions. An addition was decided to include at several places of the lexicon, `R` output if we thought that this would facilitate the understanding of the ideas and concepts presented here.

The following `R` packages are needed for explaining some of the concepts below;

```{r}
#| warning: false
library(gamlss)
library(gamlss2)
library(gamlss.ggplots)
```

We shall use the `rent99` the a main source of a [data] for the examples;

```{r}
#| warning: false
data(rent99)
```

Two of the variables in `rent99` are not needed so we they are taking them out the rest are

```{r}
da <- rent99[,-c(2,9) ]
head(da)
```

# Lexicon

################################################################################ 

::: page-break
:::

## A

#### accumulated local effects

The [accumulated local effects], [ALE], @apley2020visualizing, is a model [agnostic method] for the [interpretation] of [term]s in a [model]. It is showing how [explanatory variables] affects the predictions value of the model. It works even with correlated [explanatory variables], by analysing differences in predictions across local intervals rather than averaging whole predictions. ALE avoids issues with [multicollinearity] or [concurvity] by focusing on the change in predictions within local windows, therefore providing more accurate and unbiased global explanations for [variable importance].

::: callout-note
provide an example here
:::

#### acf

The term [acf] stands for [autocorrelation] function. The [acf] is a [diagnostics] tool for detecting [autocorrelation] in a [vector] $\textbf{x}$. In a [regression analysis] the [vector] is often the [residuals] of the [model]. It is used together with [pacf], the parcial [autocorrelation] function, to identify autocorrelation in [time series] data.

```{r}
#| warning: false
library(gamlss.ggplots)
m1 <- gamlss2(rent~area+s(yearc) + location*cheating +
            s(area, yearc, by=cheating), data=rent99, famlily=GA) 
y_acf(resid(m1))
```

#### additive smoothers

Additive smoothers occurs when the contribution of one or more continuous [term]s [smoother] is added to the rest of the terms in the equation of a model For example the [formula] $s_1(x_1)+s_2(x_2)+ s_3(x_1, x_2)$, where the $s()$s are different [smooth function]s will [fit] two main effects [smoother]s for $x_1$ and $x_2$ and a first order interaction [smoother] for for $x_1$ and $x_2$.

```{r}
#| label: fig-m0
#| fig-cap: "The fitted smoothing terms for model `m0`."
library(gamlss)
#| warning: false 
library(gamlss2)
m0 <- gamlss2(rent~s(area)+s(yearc)+s(area, yearc), 
              data=rent99, famlily=GA) 
plot(m0)
```

Smooth first order interaction models have relatively easier [interpretation].

#### additive model

An additive model occurs when the contribution of each [term] in a [model] is added to the rest of the terms in the [formula]. Let $x_1$ abd $x_2$ be two [continuous variable]s and $f_1$ and $f_2$ to be two [factor]s. The [formula] $$y \sim b_1 x_1 + s_2(x_2) + f_1*f_2 + s_{12}(x_1, x_2, \texttt{by}=f_2),$$ will fit a linear [term] for $x_1$ a [smoother] non-linear function for $x_2$, a linear first order interaction for the [factor]s $f_1$ and $f_2$ and a varied coefficient smooth term  for the first order interaction for for $x_1$ a and $x_2$, that is,  varying  $x_1$ a and $x_2$ according to different levels of the factor $f_2$.

```{r}
#| warning: false 
library(gamlss)
m1 <- gamlss2(rent~area+s(yearc) + location*cheating +
  s(area, yearc, by=cheating), data=rent99, famlily=GA) 
summary(m1)
```

The fitted smooth curves can be plotted by

```{r}
#| label: fig-m1
#| fig-cap: "The fitted smoothing terms for model `m1`."
plot(m1)
```

Note that an [additive model] is usually easy for [interpretation] but more difficult to achieve. This because in order to get an [adequate model] when you use additive terms you have to  decide in advance which [term]s should be included in the [model] and how. An [additive model] need more thinking on how to reach an [adequate model] while a [machine learning] [model] let the computer to do the hard work but makes it hard for [interpretation]. Which [model] we should trust best depends on the [purpose] of the study and the [questions] to answer. 


<!-- My personal view in-line with  in this that we should \textbf{not} let the computers decide when the life of people is stake see also [black box]. -->

#### adequate fit

We call a [model] an [adequate fit] if the [final model] in a [model selection] procedure is an [adequate model].  By [adequate model] we mean a [model] close to the [data] and  able to answer the [questions] posed by the study. How close to the data a model is can be checked by the performance of the [goodness of fit] [objective measure] and by [diagnostic tool]s in both [training] and [test] [data]. However the [goodness of fit] [objective measure] is often a relative measures in the sense that is useful for comparing between models but not to show if any of the model is [adequate fit]. This task mainly lies with [diagnostic tool]s. More specificity [diagnostics] based on [residuals]. The reason is because in most [stochastic model]s, if the the [assumptions] are correct or nearly correct, we expect the [residuals] to behave as a [white noise]. Diagnostic plots demonstrating [white noise] [residuals] are a good sign that an [adequate fit] has been achieved. In conclusion a [adequate fit] can be verified using [residuals] [diagnostics] on the [training] data set in compilation with a good performance in a [goodness of fit] [objective measure].

<!-- The question is how do we know that we reach an [adequate fit]?. -->

#### adequate model

We call a [model] an [adequate model] if the [model] represents the [data] well. That is, a model is [adequate model] if it has passed its [diagnostics] checks. A set of many [adequate model]'s is oftem called the [Rashomon set]. Within a [distributional regression] framework we have two types of [adequate model]s to consider. The first has to do of whether the [distribution] of the [response] is fitted adequately the second on whether the chosen [term]s are adequate represent the relationships in the [distribution parameters].

#### adequate distribution

Within a [distributional regression], an [adequate distribution] for the [residuals] ([z-scores]) indicates that we do not have any evidence that the assumed [distribution] for the [response] is wrong.

#### agnostic method

An [agnostic method] in [statistical modelling] is a technique which could apply to any [model] independently if they are [mathematical model]s, [agent based model]s or [algorithmic model]s. Note, however, that a lot of the techniques claimed to be agnostic may depend on the [assumptions] of the model or on the type of [objective measure] of [goodness of fit] used to [fit] the model. The [assumptions] and the [objective measure] of [goodness of fit] are interconnected with the [model]. Strictly one should defined an [agnostic method] a techniques which is not associated with any of them.

#### agent

An [agent] is the basic unit of interest in a [agent based model]. In statiscal modelling werefer to the basic units of the study as \[objects\].

#### agent based model

An [agent based model] is a simulation, [bottom up model], where the unit of interest is called an [agent]. The model is build by simulating the behaviour f the [agent]s within given enviroments.The [agent]s ar the basic unit of interest and. their behaviour is studied by assuming simple mathematical or logic rules. The application of those simple rules over time determine the long terms behaviour of the agents. Therefore important part of the model is how to set the rules ans the parameters determine the [agent] behaviour.

#### aggregation rule

By [aggregation rule] we mean how multiple predictions are combined to produce a single [prediction].

#### AIC

[AIC] stands for the Akaike Information Criterion, @Akaike73b. [AIC] it is a measure of [goodness of fit] based on [entropy] measures used to compare different fitted models. The [AIC] is defined as the [deviance] \$ + 2 \times df\$ where $df$ are the [degrees of freedom] and 2 stands for the **penalty**, see [GAIC] and [BIC]. The [model] with the minimum [AIC] is considered the best.

```{r}
AIC(m0,m1)
```

#### ALE

[ALE] is an abbreviation for [accumulated local effects]

#### algorithm

An algorithm is a step-by-step computational procedure designed to perform a specified task. For example, in [machine learning] a typically model is $Y=g(X)+\epsilon$, where $\epsilon$ is the [error]. The task of [machine learning] is to find the unknown function $g()$, which connect the [explanatory variables] with the [response].

#### algorithmic model

An algorithmic model is a model based on an algorithm. In [regression] typically an algorithmic model trying to model $X \rightarrow Y$, through an unknown function $g()$ i.e. $Y=g(X)$. No explicit assumptions are made for the unknown function $g()$ but a lot of implicit [assumptions] depending on the type of algorithm used. Note that an [algorithmic model], like a [mathematical model], can be a deterministic or a [stochastic model]. The [stochastic model] can be written as; $Y=g(X)+ \boldsymbol{\epsilon}$ where the last term in the equation is the [error], that is, a \[random\] variable usually a [white noise]. The [error] is the stochastic part of the [model].



#### algorithmic modelling



#### Archimedean copulas

The [Archimedean copulas] are a wide class of families of copula with subclass;

-   the [Clayton copula] which cal model strong lower tail dependence, that is, useful when joint small values matter.

-   the [Gumbel copula] supporting strong upper tails and its useful for modelling extreme values.

-   the [Frank copula] with symmetric dependence and not fat tail dependence.

-   the \[Joe copula\] with strong upper tail dependence and more flexible than [Gumbel copula]

-   the [extreme value copulas] suitable for modelling jointly extreme values. (Gumbel–Hougaard, Galambos, Hüsler–Reiss) Popular in hydrology, climate extremes and Risk analysis.

-   the \[vine copulas\] (or pair copula constructions) whicjh are highly flexible, built from bivariate copulas with types: i) C-vines copula ii) D-vines copula and iii) R-vines copula. All have the advantages that handle high dimensions couls mix different copula families and have very flexible dependence structures. They are widely in Finance, Insurance and Machine learning.

-   the [hierarchical Archimedean copulas] (HAC) which allow nested Archimedean copulas, clustering of dependence and in genaral are more flexible than single [Archimedean copulas]

-   the \[empirical nonparametric copulas\] Empirical copula and Bernstein copula with advantages of fewer assumptions and [data]-driven.

-   the \[special purpose copulas\] like the \[Plackett copula\] the \[FGM copula\] (Farlie–Gumbel–Morgenstern) whicj allow limited dependence and the Marshall–Olkin copula with asymmetric dependence.

::: callout-note
No definition is given ans more work needed here
:::

#### association measures

see [measure of association].

#### assumptions

Assumptions are axiomatic statements needed to be accepted for the model to work. Models need assumptions because of their simplified nature. The important thing behind [assumptions] is that if the [assumptions] are correct then the model can be adequate and probably useful. There are **explicit** and **implicit** assumptions. The **explicit** assumptions are usually mathematical ones and easy to check using [diagnostic tool]s. The **implicit** assumptions more common in [algorithmic model]s are more difficult to check. **Incorrect** assumptions could lead to questionable scientific discoveries. For an [agent based model] the assumptions are about the behaviours of the [agent]s. For [distributional regression] model there are two set of [assumptions]; i) about he distribution of the respose and ii) how the [explanatory variables] affect the [distribution parameters].

::: callout-note
Maybe as an example put the assumptions of the [linear model] here
:::

#### autocorrelation

The term [autocorrelation] in a vector $\textbf{x}$ implies that sequential values of $\textbf{x}$ depend on previous values. Autocorrelation is very common on [time series] data and can be detected using [acf] and [pacf] functions.

In [distributional regression] one should check whether the [z-scores] are autocorrelated especially when the data ar time series ones. Checking autocorrelaty ion can be done acheoved eadily using the `gamlss,.ggplts` package with `resid_plots()` ans option `theme="ts"`;

```{r}
#| warning: false 
library(gamlss.ggplots)
resid_plots(m1, theme="ts")
```

#### averaging models

In [averaging models] the idea is is to select a [final model] from a \[stack of models\] by averaging the [model]s. There are a lot of ways to average [model]s see also [model average] and [stacking].

::: callout-note
example?
:::

################################################################################ 

::: page-break
:::

## B

#### backfitting

The [backfitting] algorithm is an algorithm discussed by @HastieTibshirani90 for fitting more that one smoother in a [formula] for a [model].For distributional regression is explained in Chapter 3 of @Stasinopoulosetal2017.

#### bagging

Bagging, @breiman1996bagging, refers to [bootstrapping] followed by an [averaging models] procedure. That is, $B$ models are fitted to $B$ bootstrap [data partition]s and the resulting models are then averaged to greate one model. The \[random forest\] models are [bagging] models since they are a collection of [regression tree] models witch then averaged to crate the final model.

#### base learner

A [base learner] is a single [model] in the [ensemble] of models. The derminology is used in boosting.

#### Bernoulli distribution

The [Bernoulli distribution] is special case of the [binomial distribution] when $n=1$. A Bernoulli \[random\] variables has range of values $0$ or $1$. The Benrouli distribution is ideal for modelling \[classification models\] which heve only two outcomes e.g. "yes", "no" , "dead", "alive", "presend" absend". The expected value of a Benrouli \[random\] variable is $\mathbb{E}(Y)=p$ with variance $p(1-p)$. A Bernoulli [response] variable is modelled using **logistic regression**. The [Bernoulli distribution] is a specuoal case of the [binomial distribution] therefore both belong to the [exponential family].

@fig-bernoulli shows three realization of the [Bernoulli distribution] at different levels of probability $p=(0.1,0.3,0.5)$

```{r}
#| fig-width: 4
#| fig-height: 4
#| label: fig-bernoulli
#| warning: false
#| fig-cap: "The Bermoulli distribution with differenrt values of p=(0.1,0.3,0.5) and n=1"
library(gamlss.ggplots)
family_pdf(BI, mu=c(0.1,0.3,0.5), to=1, title="Bermoulli p=c(0.1,0.3,0.5) an n=1")
```

::: callout-note
Is there a bug in the function? The probabilities should be the other way around.
:::

#### Bayesian

See [Bayesian statistics] and [Bayesian method].

#### Bayesian statistics

By [Bayesian statistics] we mean statistical analysis using the [Bayesian rule] for inference.

#### Bayesian method

A [Bayesian method] is a statistical method using the [Bayesian rule] as a mode of inference,

#### Bayesian rule

The [Bayesian rule] defines the posterior distribution of parameter $\boldsymbol{\theta}$ given a [sample] $\textbf{y}$ as: $$ f( \boldsymbol{\theta}|\textbf{y}) = \frac{f(\textbf{y}|\boldsymbol{\theta}) f(\boldsymbol{\theta})}{f({\textbf{y}})}$$ where $f(\boldsymbol{\theta})$ is the prior distribution of the parameter, $\boldsymbol{\theta}$, and $f( \textbf{y}|\boldsymbol{\theta})$ is the probability of observing the sample $\textbf{y}$, that is the [likelihood] function.

#### bias

The [bias] measures the systematic difference between an [estimator]’s average value and the \[true parameter\]. Bias appear in several place in statistical analysis Let $\hat{\theta}$ to be an [estimator] of the parameter $\theta$.$$\text{bias}(\hat{\theta})
 = \mathbb{E}[\hat{\theta}] - \theta $$ The [estimator] is called unbiased if $\mathbb{E}[\hat{\theta}] = \theta$. The [bias] in [bootstrap] is defined as $$\widehat{\text{Bias}}_{\text{boot}}
= \overline{\theta^*} - \hat{\theta}$$ where $\hat{\theta}$ is the [estimate] using the original data and $\overline{\theta^*}$ is the mean of the $B$ \[estimate\[\]s of $\theta$ in each [bootstrap] [fit]. The [bias]–variance trade-off in a machine learning model $Y=f(X)+\epsilon$ is has to do with the expected prediction error which decomposes as: $$\mathbb{E}\big[(Y - \hat{f}(X))^2\big]
= \text{Bias}^2 + \text{Variance} + \sigma^2$$ where $\sigma^2$is the assumed (constant) variance or the [error] $\epsilon$ while $\text{Variance}$ is the variance of the estimator. High [bias] implies that the model is too simple, [under fitting], while high variance implies that the model is too complex, [over fitting].

#### BIC

BIC is the Bayesian information criterion of @Schwarz78. Within a [distributional regression] model the BIC can be used to compare different fitted models. The BIC is also refer to also as [SBC], Schwarz Bayesian Criterion. The BIC is defined as [deviance] $+ \log(n) \times DF$, when $n$ is the number of observations in the [data], and $DF$ are the [degrees of freedom]. See also [GAIC].

#### binomial distribution

The pdf of a binomial distributed \[random\] variable is: $$f(Y|p)= \binom{n}{p} p^{p} (1-p)^{n-p}$$ where $Y$ takes values in the [range] $0,1,2,\ldots,n$, $n$ is called here the **binomial denominator** and the parameter $p$ is a probability parameter taking values $0<p<1$. Note that $\binom{n}{p}$ can be written also as;\
$$ \binom{n}{p} =\frac{\Gamma(n+1)}{\Gamma(y+1) \Gamma{(n-y+1)}}$$ For more details see pp. 521-522 of @Rigbyetal2019. The expected value of the [distribution] is $\mathbb{E}(Y)=np$ and the variance is $\mathbb{V}ar(Y)=np(1-p)$. @fig-binomial show the three different binomial distributions with binomial denominator equal to 10 and different probabilities at

```{r}
#| label: fig-binomial
#| fig-cap: "The binomial distribution with different values of p=(0.1,0.3,0.5) and n=10"
#| warning: false
library(gamlss.ggplots)
family_pdf(BI, mu=c(0.1,0.3,0.5), title="binomial p=c(0.1,0.3,0.5) and n=10")
```

Note that in the `gamlss.ggplots` documentation the parameter of the [binomial distribution] called here as $p$ is denote as `mu`. The binomial denominator in the function `family_pdf` can be specified in by the argument `to`. In @fig-binimial it take the default value which is 10.

#### black box

A [black box] is a [model] with difficult [interpretation]. Few of [machine learning] models are [black box]es. There are two reason for black box model i) the estimation of the function $g()$ is too complex to explain. ii) there are proprietary reasons d=so the modfel remain a mystery. The [questions] of the problem should determine whether a [black box] [model] is appropriate. @rudin2019stop argued "stop explaining black box machine learning models for **high stakes decisions** and use [interpretable model]s instead". The argument came from the fact that among all [adequate model]s e.g. the [Rashomon set] few are interpretable [@rudin2024amazing].

#### bootstrap

See [bootstrapping]

#### bootstrapping

The method of [bootstrapping], @efron19791977, @efron1992bootstrap, is a way to fit multiple models to a single [data] set by repeatedly [data partition]ing using re-sampling with replacement. The multiple [fitted model]s can be used to obtain [information] about the variability or other properties of the [parameters] in the [model], e.g. [SE], [CI], [bias]. This is done by using the resulted bootstrap distribution of the [parameters], see @fig-data_bootstrapping describing the [bootstrap] process. The [bootstrap] distributions provide all the extra [information] required about the parameters of the [model]. In this sense, [bootstrapping] complement [Bayesian] statistical [fit]s which use [MCMC] to produce posterior distributions of the [parameters]. In this case the [information] about the variability comes from \[prior distribution\] [assumptions] resulting posteriors simulated samples of the [parameters].

```{mermaid}
%%| fig-width: 2
%%| label: fig-data_bootstrapping
%%| fig-cap: Bootstrap-partition of data in order to get more information about the parameters of te model."
flowchart LR
    A[data] --> B[Re-sample <br/> with replacement]
    B --> C1[data 1 ]
    B --> C2[data 2]
    B --> C3[...]
    B --> C4[data  B]

    C1 --> D1[fit model 1]
    C2 --> D2[fit model 2]
    C3 --> D3[...]
    C4 --> D4[fit model B]

    D1 --> E[bootstrap <br/> distribution <br/> of parameters]
    D2 --> E
    D3 --> E
    D4 --> E
```

Bootstrapping is based on [data partition]. The [data] are partitioned $B$ times, with replacement, the same [model] is fitted $B$ times so in the end we have samples of lenght $B$ for all [parameters] of interest. Those samples can be use to construct [bootstrap] distributions of the [estimator]s of the [parameters], the [fitted values] and the [residuals] of the [model]. Averaging those values to obtain a unique value sometimes refer to as [bagging], @breiman1996bagging. A good introductory book about the classical [bootstrap] and its theory can be found in @EfronTibshirani93.

For [GAMLSS] models there are two ready make functions to be use for [boosting]

-   `NonParametricBoot()`: this function is doing the classical [bootstrapping] where the data are partitioned with replacement $B$ times.

-   `BayesianBoot()`: this functions is doing the [Bayesian] [bootstrapping], @rubin1981bayesian where the model is fitted $B$ with different prior weights

::: callout-note
provide examples here
:::

<!-- In the following example we use the   -->

<!-- ```{r} -->

<!-- library(gamlss2) -->

<!-- m1 <- gamlss(rent~area+pb(yearc)+location, data =rent99, family=GA) -->

<!-- #m1 <-gamlss(y~x+qrt, data=aids, family=NBI()) -->

<!-- registerDoParallel(cores = 10) -->

<!-- B1 <- BayesianBoot(m1) -->

<!-- B1 -->

<!-- # you can save it  -->

<!-- # i.e. BB=summary(B1,"mu") -->

<!-- stopImplicitCluster() -->

<!-- ``` -->

#### boosting

The methodology of [boosting] provides an alternative estimation technique. It was developed in [machine learning], @schapire1990strength and @freund1995boosting, to create a single [fitted model] by aggregating many **complementary** sequential simple models. @schapire1990strength have shown that **weak** [learner]s can be boosted into a **strong** [learner]. A [learner] is an individual [model]. A weak [learner] is a [model] which its predictions are on average a bit better that a [model] which has a change of 1/2 to predict the right result. The idea is that a simple [ensemble] of easy to [fit] [model]s, **complimenting** each other can be better predictor than a single complicated [model]. The [model]s could compliment each other if sequentially [fit]s different characteristic of the [data] better. This can be achieved if sequential [fit]s use [prior weights] weighing the [residuals] of the previous [fit] differently e.g. with more weight for larger [residuals].

> `garnering wisdom from a council of fools`.
>
> -- Schapire and Freund (@schapire2013boosting)

The statistical part of the theory on boosting was developed by @breiman1997arcing, @friedman2000additive and generalised by @friedman2001greedy by introducing the [gradient boosting] concept. The main advantage of the statistical [boosting] compare the more classical techniques of [statistical modelling] is that [boosting] includes [model selection] of [term]s as part of the [algorithm] and also can cope with situations where there are more [variables] than [observations] e.g. $r \ge n$.

The integration of statistical [boosting] to [distributional regression] [model]s it was done by @Mayretal2012, implemented to the `R` package `GAMboostLLS`. More explanation how to model can be found in @Hofneretal2014 and in Chapter 7 of @stasinopoulos2024generalized. The algorithm in this case fit weak [learner]s (simple smoothing models if smoothing is required otherwise linear model) several time but each individual [fitted model] contributes only a small percent to the [final model] e.g.10%. This percentage is one of the [hyper parameter]s of the boosting method, the other more important [hyper parameter] is how many time the algorithm is repeat. The later is the main \[smoothing\] parameters of the [boosting] procedure. To determine this \[hyper parameters\] a [cross validation] can be perform which could lead to an [adequate model].

<!-- [boosting] where a lot of week models are fitted to a single data set in such a way that the averaged models supplement each other. This is done by taking into the account the [residuals] of the previously [model fitting]; [bagging] when $B$ models are fitted to $B$ bootstrap [data partition]s and the models are averaged; [stacking] when when $B$ different [model]s are fitted to a single data set (no partition) and the models are averaged. -->

::: callout-note
We need an example here
:::

#### bottom up model

A [bottom up model] is a [model] starting at the micro level behaviour of the [subjects] and how they interact with each other in order to check the overall global behaviour on the [variables] of interest. A typical example of this type of model is the [agent based model] where the individual behaviour of the [agent]s affect the overall behaviour variables. A agent based model is a [simulation model] where the behaviour of variables is examine after the simulation of the model several times.

#### bucket plot

A [bucket plot], @de2022bucket, is a [diagnostic tool] which can detect [skewness] and [kurtosis] in any [vector] in the [data] but more important in the [residuals] ([z-scores]) of a [distributional regression] [model]. Detection of [skewness] and [kurtosis] in the residuals of a [distributional regression] [model] amounts to detection of [skewness] and [kurtosis] in the [response] variable. There two types of [bucket plot]s: i) the first is based on [moment] [summary statistic]s; the second on [centile] based [summary statistic]s. The functions `moment_bucket()` and `centile_bucket()` of the package `gamlss.ggplots` can be used respectively to produce a [bucket plot], in `R`.

@fig-mom_bucket shows a [moment] [bucket plot] of the model `m0` fitted earlier in the section [additive smoothers] where two [smooth function]s [main effect]s `s(area)+s(yearc)` and one [first order interaction], `s(area, yearc)`, were fitted to the [response] Munich `rent` taken from the [data.frame] `rent99` using a Gamma (`GA`) distribution.

The moment based [bucket plot] in @fig-mom_bucket plots the transformed [moment] [skewness] of the residuals of the model `mo` against the transformed [moment] excess [kurtosis].

```{r}
#| label: fig-mom_bucket
#| fig-cap: "The moment bucket plot of the residuals of model `m0` "
#| warning: false
library(gamlss.ggplots)
moment_bucket(m0)
```

```{r}
#| label: fig-cen_bucket
#| fig-cap: "The centile bucket plot of the residuals of model `m1` "
#| warning: false
centile_bucket(m1)
```

Here we up data the [distribution] of the response from the two parameter `GA` to the four parameter `BCTo`.

```{r}
#| label: fig-model_mom_bucket
#| fig-cap: "The moment bucket plot of the reiduals from models `m0`, `m1` and `m2`.  "
#| warning: false
m2 <- update(m1, family=BCTo)
model_mom_bucket(m0, m1, m2)
```

::: callout-note
This needs more work
:::

################################################################################ 

::: page-break
:::

## C

#### candidate model

The [candidate model] is next model to be fittes [fit] in the line of all possible models to be selected in a [step wise] procedure and it is compared to the [current model].

#### categorical variable

A [categorical variable] is a vector in the data which takes only few distinct values categorising the \[objects\] into different classes. In statistics a [categorical variable] is called a [factor] and its values are called the \[levels\] of the [factor].

#### centile

A [centile] value is defined as $$100 \times \text{quantile}.$$ Since a [quantile] is taking values from 0 to 1 a [centile] is defined in the interval 0 to 100 for example the [quantile] at $0.50$ or 50% [centile] is the [median]. In practice the term [centile] is used as synonymous to [quantile]. A [centile]/[quantile] is a characteristic of both of the [distribution] of a \[random\] variable and of a [vector] in the [data]/[sample]. Centiles in the leter case can be defined through the [empirical cdf].

#### centile based measure

A [centile based measure] is equivalent to a \[quantile based measure\]. It describes a [characteristics of the distribution] based on [quantile]/[centile] rather [moment].

For example $\bar{x}$ can be used as estimate of the mean $\mathbb{E}(X)$ of the theoretical [distribution] assumed for $x$ i.e. $\mathbb{E}(X)= \int_{-\infty}^{\infty} X f(X) dx$, where $f(X)$ is the assumes [distribution] for the [vector] $x$.

#### centile estimation

Centile estimationis another term for [reference curves] fitting.

#### censored response

A [censored response] is a [response] variable which could takes [interval values],

#### censored values

A \[random\] variable which we do not know its exact value but that only that it have been fallen within a known interval it said to have [censored values] or [interval values].

#### cdf

A cdf is the **commutative distribution function** of a random variable $Y$, usually denoted as $F(Y)$. The first derivative of the cdf define the probability distribution function, pdf of $Y$ i.e. $f(Y)=F'(Y)$ For a [distributional regression] where the [response] is assumed to have a proper [distribution] [pdf] he [cdf] is usually refer to as the \[commutative distribution\] function of the response.

#### Clayton copula

The [Clayton copula] for two random variable $u_1$ and $u_2$ both taking values in the [range] $[0,1]$ is defined as; $$C_\theta(u_1,u_2)
=
\left(u_1^{-\theta} + u_2^{-\theta} - 1\right)^{-1/\theta}$$ where $\theta$ is the parameter of the copula. The [Clayton copula] belongs to to the [Archimedean copulas] family. It models only positive dependence and only lower tail and its asymmetric with stronger lower tail. The interpretation of the parameter $\theta$ is when $\theta = 0$ implies independence, larger $\theta$ stronger dependence. It emphasises joint small values and it is related with Kendall’s $\tau$: $\tau = \frac{\theta}{\theta + 2}
\quad \Rightarrow \quad
\theta = \frac{2\tau}{1-\tau}.$

#### concurvity

The term [concurvity] is the nonlinear analogue of [multicollinearity]. In particular, in model which use [smoother]s like the {GAMs\], [concurvity] occurs when one [smooth term] can be approximately expressed as a nonlinear function of one or more other [smooth term]s. So [concurvity] implies nonlinear dependence between [explanatory variables]. For example if two [explanatory variables] carry essentially the same information in a nonlinear way, the [model] has difficulty distinguishing their individual effects. For example let a GAM model be $g(\mathbb{E}[Y]) = \beta_0 + f_1(x_1) + f_2(x_2) + \cdots$ Concurvity is high if $f_1(x_1) \approx h\!\left(f_2(x_2), f_3(x_3), \dots\right)$ for some (possibly nonlinear) function $h()$. The consequences for [concurvity] are; unstable [fit]s or poorly identified [smooth term]s; inflated [CI] bands; wigglier [smooth term]s and finally more difficult [interpretation] for the model's individual effects. Not-linear [correlation coefficient] could be possiblely identify [concurvity] at a [pre-data analysis] stage.

#### coefficients

The [coefficients] are [parameters] in a [model]. In [distributional regression] we refer to as [coefficients] when they are the [parameters] describing the relationship between the [distribution parameters] and the [explanatory variables] to distinguish them from the [distribution parameters].

#### continuous distribution

A [continuous distribution] is a [distribution] function, [pdf], of a \[random\] variable $Y$ taking values in the real line. The only property a [continuous distribution] has to have is that if is integrated with respect to the random variable it should add up tp one i.e. $\int_{-\infty}^{\infty} f(Y)dy=1$. There are three types of continuous distributions depending on the [range] of the continuous random variable $Y$;

i)  $(-\infty , \infty)$, continuous in the real line;
ii) $(0, \infty)$, continuous in the positive real line;
iii) $(0 , 1)$ continuous on a finite interval in the real line;

Next we show plots the different types of [continuous distribution]s. We start with the normal [distribution] in which has two parameters $\mu$ the mean and $\sigma$ the standard deviation and which is defined on $(-\infty , \infty)$

```{r}
#| label: fig-normal
#| fig-cap: "The normal distribution with differenrt values of sigma=(1,1.5,2) and mu=0"
#| warning: false 
library(gamlss.ggplots)
family_pdf("NO", mu=c(0, 0, 0), sigma =c(1,1.5, 2), from=-5, to=5,title="Normal with mu=(0,0,0) and sigma=(1,1.5,2)")
```

Similarly the gamma [distribution] in @fig-beta, has two parameters $\mu$ the mean and $\sigma$a scale parameter but its defined on the positive real line $(0, \infty)$:

```{r}
#| label: fig-gamma
#| fig-cap: "The gamma distribution with differenrt values of mu ar 1 and sigma=(1 ,0.8, 1.5)."
#| warning: false 
library(gamlss.ggplots)
family_pdf("GA", mu=c(1, 1, 1), sigma =c(1,0.8, 1.5), from=0.01, to=5,
        title="Gamma with mu=(1,1,1) and sigma=(1,0.8, 1.5)")   
```

The beta [distribution] in @fig-beta, is defined on the real line $(0, \infty)$ and two parameters $\mu$ the mean and $\sigma$ a scale parameter:

```{r}
#| label: fig-beta
#| fig-cap: "The beta distribution with differenrt values of mu=(0.2, 0.5, 0.8) and sigma=(0.2 ,0.8, 0.3)."
#| warning: false 
library(gamlss.ggplots)
family_pdf("BE", mu=c(.2, .5, .8), sigma =c(0.2 ,0.8, 0.3), from=0.01, to=0.99,
           title="Beta with mu=(.2, .5, .8) and sigma=(0.2,0.8, 0.3)") 
```

As rule the more parameters exist in a [distribution] the more flexible the [distribution] is.

Note that any random variable in the interval $(\alpha, \beta)$ can be transformed to a [distribution] in the interval $(0 , 1)$. Also note that any [distribution] with [range] $(-\infty , \infty)$ can be **log** or **logit** transformed to a [distribution] in the positive real line $(0, \infty)$ or to the fine interval $(0 , 1)$, respectively.

#### continuous variable

There are two occasions we use the term [continuous variable]:

-   a [continuous variable] in the [data] it means that the [vector] in the data can possible take a lot of different values e.g. height, weight.

-   a [continuous variable] in [distribution]s it means that the [range] of the \[random\] variable $X$ takes values in the real line.

Note that in the later case there are three different possible [range]s:

i)  the real line; $(-\infty , \infty)$, ;
ii) the positive real line; $(0, \infty)$,
iii) continuous on a finite interval $(0 , 1)$.

#### compositional data

By [compositional data] in regression we mean [response] variables which parts of a whole sum to 1 or 100%. Compositional [response] variables need special handling within standard regression. A compositional [response] has the property that $\mathbf{y} = (y_1,\dots,y_D), \quad y_i > 0,\quad \sum_{i=1}^D y_i = 1.$ A compositional [response] within [distributional regression] can be modelled using the Dirichlet distribution which is a generalization of the beta distribution, the same way as the multinomial distribution is a generalization of the \[binomial\] distribution.

#### characteristics of the distribution

Each [distribution] has its own properties. We called those properties the [characteristics of the distribution]. Within a [distributional regression] framework and for better [interpretation] we should be ware with both the properties of the [distribution parameters] but also other [characteristics of the distribution] itself. The [characteristics of the distribution] can be defined i) using [moment]s or ii) using [quantile based measures].

#### classification model

A [classification model] is an [unsupervised learning] [model] in which the output that is the [response] is a [factor] with unknown categories. The model tries to guess what is the best possible value for the response given the [explanatory variables]. The models for [distributional regression] are all [supervised learning model]s in which a [response] exist in the [data].

#### copula

The [copula] methodology is a way of constructing a [multivariate distribution] binding its [marginal distribution]s with a [copula]. The methodology is based on \[Sklar’s theorem\]. It is a convenient way of introducing multiple responses in a \[distributional. regression\] [model].

While [copula] can be defined in higher dimesions here for clarity we are concentrate in 2-dinemseions. Let $X_1$ and $X_2$ two random variables with marginal [pdf] distributions $f_1()$ and $f_2()$ and marginal [cdf]s $F_1()$ and $F_2()$, respectively. Using the [Sklar's theorem] the joint [pdf] of the variables $X_1$ and $X_2$ can be written as $$f(X_1, X_2)= C[F_1(X_1, F_2(X_2)] f_1(X_1) f_2(X_2),$$ where the function C() is a [copula], that is, a [cdf] function of two \[random\] variables $u_1=F_1(X1)$ and $u_2=F_1(X2)$ defined in the [range] of the two dimensional cube $[0,1]^2$. Note that for the construction of the [likelihood] function of the joint [distribution] of two random \[random\] variables $X_1$ and $X_2$, assuming that the [pdf]'s and the [cdf]'s are easy to evaluate, we only need the tyoe of the copula function $C()$ to use.

::: callout-note
We need to say someining about the types, the generalazation to motre than two dimensions , [vine copula] and minimal and maximal copula
:::

There are different types of copula; i ) [elliptical copulas] ii) [t copula] iii) Archimedean copulas

In general when someone tries to construct a [multivariate distribution] using copula she/he should look the tail behaviour, symmetry, dimensionality and interpretability of the copula.

#### correlation coefficient

A [correlation coefficient] is a pairwise [measure of association] between two \[continuous variables\] in the [data].

@brito2025exploring

#### collinearity

We have [collinearity] in a [design matrix] of a [model] if there is a linear depedance between the columns of the [design matrix].

#### confidence interval

::: callout-note
defintion
:::

#### CI

[CI] is and abbreviation for [confidence interval].

#### count data distribution

See [discrete distribution]

#### continuous rank probability scores

::: callout-note
We need to define CRPS
:::

#### constant

A [constant] in a model matrix is synonymous with the [intercept].

#### cross validation

The idea behind [cross validation] is that the [model] performance is validated using a [measure] of [goodness of fit] on [out of bag] [data] that were not be used in the [fit] the [model].

#### CRPS

The expression [CRPS] is an abbreviation for [continuous rank probability scores] which are a [measure] of [goodness of fit] appropriate for [distributional regression] [model]s.

#### current model

The [current model] is the model which is compared to the the \[canditate model\] in a [step wise] selection procedure.

################################################################################ 

::: page-break
:::

## D

#### data

The term [data] is a generic term to describe object which contain some kind of [information]. It used to mean a file with many numbers, but [data] today could have different forms. Could be **texts**, **pixels**, or any other form containing some [information] to be extracted . The [model] tries to extract the [information] from the [data]. Note that at a pre-[statistical modelling] stage we can still extract useful information from the [data] to actually help us with the statistical modelling. The package `gamlss.prepdata` is design to help in this direction. Within [distributional regression] [model]s most of the data used are [tabular data]. Note that [data] sets in the statistical programming language `R` are refereed to as [data.frame]s.

#### data.frame

A `data.frame` is the way a [data] set is refer to in the `R` statistical programming language.

#### data partition

The term [data partition] has two different meanings. The fist has to do with [statistical modelling] the second on looking at whether the variables involved in a [model] behave differently at different parts of the [data].

Data partition in the process of [statistical modelling] helps the model building process, [model] [interpretation], the checking for [over fit] and also helps to improve the [statistical inference] by providing extra [information] about variations in the parameters. There are different types of data partition; a **single** partition of a data set provides holdout samples for prediction and validation purposes. A **multiple** partitions as for example [bootstrapping] and [K-fold cross validation] to help inference.

```{mermaid}
%%| fig-width: 2
%%| label: fig-data_split
%%| fig-cap: Different ways of partitioning data in order to get more information aboout the model."
flowchart TB
  A[Data] --> B{Holdout} 
  A --> C{K-fold-CV}
  A --> D{Bootstrap}
  B --> E[Training]
  E --> F[Validate]
  F --> G[Test]
  D --> H[Non-parametric]
  D --> K[Bayesian]
  C -->  L[LOO]
```

The second meaning of [data partition] tries to answer the following question. Is there a way to partition the data in such a way that the relationships between the variables in the [data] behave differently?; or more generally can I divide the [data] in such way that different models can apply to different parts of the [data]?. Models like [regression tree]s try to separate the [data] in such a way that the resulted subclass are homogeneous by fitting different constant models withing each part.. $\ldots$

#### data partition based model

A [data partition based model] is a [model] which is based on the assumption that different [variables] in the data affect the [subjects] differently at different parts of the [data]. A [regression tree] is a typical example of a [data partition based model] where the effect of the [response] variable is changing according different values of the explanatory variables. The effect of the explanatory variables on the response is piece wise constant. More complicated models could assume piece-wise linear or more complicated relationships. Th ebasic idea remain the same the [variables] affect the [subjects] differently at diffrent parts of the [data].

#### data analysis

Data analysis is the art of extraction information from the [data]. In any [data analysis] the first question any researcher has to ask is whether the [data] or the [model] could answer the [questions].

#### data generating mechanism

The [data generating mechanism] is a set of assumptions on how the [data] are generated. It is often difficult to check those [assumptions] because different [data generating mechanism]s could possible lead to similar data sets. That is, a [Rashomon set] where different model perform adequately for given data set. In [distributional regression] often the [data generating mechanism] is the assumption abouth the [distribution] of the [response] given the [explanatory variables].

#### data modelling


#### degrees of freedom

The [degrees of freedom] of a model measure the complexity of the model. For mathematical parametric models the degrees of freedom are the number of independent parameters used in the model. For mathematical [smooth model]s the degrees are defined as the diagonal elements of the smoothing matrix i.e. $\hat{\textbf{y}}= S(\textbf{x})$ where $\hat{\textbf{y}}$ are the [fitted values] of the smooth function and $\textbf{x}$ is the [explanatory variables]. For algorithmic models the degrees of freedom often are difficult to calculate.


#### design matrix

By [design matrix] we usually refer to the matrix $\textbf{X}$ containing all relevant explanatory variables. Note that for distributional regression model each paramerter of the [distribution] could have its own design matrix i.e. $\textbf{X}_{\theta_k}$

#### deviance

The [deviance] is a [objective measure] of [goodness of fit] and defined as $-2 \ell(\boldsymbol{\theta})$, that is, minus twice the [log likelihood]. The [deviance] can be defined in both the [training] or the [test] [data] so we can have a [training deviance] and [test deviance]. The deviance evaluated at the training data, the ([training deviance]) is used to [fit] a [model]. The [test deviance], evaluated at the [test] [data] is used for model comparison. In [GAMLSS] a penalised form of the the [training deviance], the Generalise Akaike Information Criterion, [GAIC], often is used for model comparison. The deviance can be seeing as an [empirical risk] measure based on [information criterion] concepts. It is a [summary statistic], because it is a sum of the individual [deviance increments] and therefore an overall [measure] of [goodness of fit]. It tell us how well the conditional [distribution] of $D(Y|\boldsymbol{\theta})$ fits the [data] overall. It does not tells whether the tail or the middle of the [distribution] is fitting well. To do that we need a focused [test deviance]. The [deviance increment]s may help to obtain such information.

#### deviance increment

see [deviance increments]

#### deviance increments

In [distributional regression] the [deviance] is defined as $-2 \ell(\boldsymbol{\theta})= \sum_{i=1}^n -2 \log f(y_i|\boldsymbol{\theta}_i)$ where $f(y_i|\boldsymbol{\theta}_i)$ is the assumed [pdf] for the [response]. The [deviance increments] are the individual values $-2 \log f(y_i|\boldsymbol{\theta}_i)$ which make up the deviance. The [deviance increments] can be used as [diagnostic tool] to identify observations in which the ditribution did not fot well.

```{r}
#| label: fig-deviance-incr
#| fig-cap: "A typical plot of deviance increments against the obsevation number." 
library(gamlss.ggplots)
fitted_devianceIncr(m1)
```

#### density function

At a theoretical level a [density function] is the [pdf] of a \[random\] variable. At the [sample] level a density function of a [vector] in the [data] is an empirical [distribution] function of a variable in the [data] obtain using smoothing techniques. In thios case the [density function] is a smooth [histogram].

```{r}
#| label: fig-hist-density
#| fig-cap: "An estimated density funtion on top of a histogram for the variable the price of `rent` in the Munich `rent99` data set." 
#| warning: false 
library(gamlss.data)
library(gamlss.ggplots)
y_hist(rent99$rent)
```

#### diagnostic tool

A [diagnostic tool] is one of the [diagnostics] used in statistical analysis, for more details see [diagnostics].

#### diagnostics

The [diagnostics] are statistical or graphical tools for helping to check the [assumptions] of a fitted [model]. Within [distributional regression] [diagnostics] can help to identifying whether the [distribution] of the [response] is fitted well or whether the [term]s in the different [distribution parameters] models are fitted appropriately.

#### discrete distribution

A [discrete distribution] is [distribution] function [pdf] of a \[random\] variable which takes only integer values i.e. $0,1,2,\ldots, 10$. Another name for a [discrete distribution] is [count data distribution]. The only property that any [discrete distribution] must have is that it should sums up to one. $\sum_{i=1}^{\infty}  f(y_i)=1$. There are mainly two types of [discrete distribution]s depending on the [range] of the discrete \[random\] variable involve i) infinite count ii) finite count [distribution]s. The most common example of an infinite count [distribution] is the [Poisson distribution] and the most common example of the finite count is the [binomial distribution].

#### discrete variable

We refer to a \[random\] variable as a [discrete variable] if its values are on th integer set of values, e.g. $0,1,2, 3, \ldots$. A [discrete variable] can have a finite [range], e.g. $0,1,2,3$ or an infinity [range] e.g. $0,1,2,\ldots.$

#### distribution

The term [distribution] refer to a probability [distribution] function [pdf], $f(Y)$. The only property for $f(Y)$ is required is that it should sum up to one. In distributional regression we write the [pdf] of the [response] as $D(Y | \boldsymbol{\theta})$ not $f()$ a notation which could be used for describing the relationships between the [explanatory variables] and the [response]. We are also emphasising that the [pdf] of the response is a function the different [distribution parameters], $\boldsymbol{\theta}$. The function $D(Y | \boldsymbol{\theta})$ describes how the behaviour of the [response] variable is affected by the [explanatory variables] and it is the main [stochastic] component of a [distributional regression].

#### distribution parameter

See [distribution parameters].

#### distribution parameters

Within a [distributional regression] we use the term [distribution parameters] as almost synonymous to [distributional parameters] to refer to the parameters $\boldsymbol{\theta}$ in the [distribution] of the [response] $D(y|\boldsymbol{\theta})$, see also [distributional parameters].

#### distributional parameters

Theoretical distributions depend on [distribution parameters] $\boldsymbol{\theta}$ where $\boldsymbol{\theta}=(\theta_1, \theta_2, \ldots, \theta_K)$ is a [vector] of length $K$. The more (independent) [distribution parameters] exist in a [distribution] family the more flexible the [distribution] is. For example one parameter distributions can only model one characteristic of the [distribution] of the [response] mainly the [location parameter].

#### distributional regression

A distributional regression model is an [input-output model] model in which the response $Y$ is assumed to have a [distribution] in which all the parameters of the [distribution] could depend on explanatory variables. This can be represented as $X \rightarrow D(Y|\boldsymbol{\theta}(X))$ where $\boldsymbol{\theta}$ are the k parameters of the distribution.

#### diversity

By [diversity] we mean the qualitative differences between [model]'s or [base learner]s.

#### dummy variables

A set of [dummy variables] is a set of binary 0 and 1 [vector]s indicating whether certain conditions are present (1) or not (0). Any [factor] in a [model] is represented by a set of [dummy variables] in the [design matrix] of the [model]. The number of columns in the [dummy variables] representation of a factor are the number of [level]s of the [factor] minus one to avoid [collinearity] with the [intercept] the vector of ones representing the [constant] in the [design matrix].

#### dummy vectors

In the [design matrix] of a model [factor]s are represented as a set of [dummy vectors]. Note the the number of dummy variables are the number of levels of the factor minus 1, The first level is taking out to avoid collinearity with the fits colum of the desegmn matrix which represent the [intercept] in the model.

```{r}
library(gamlss)
data(rent99)
head(with(rent99,model.matrix(formula(~area+location))), 15)
```

################################################################################ 

::: page-break
:::

## E

#### empirical cdf

The [empirical cdf], [ECDF] is the cumulative function function of any continuous or ordered categorical variable in the [sample], ([data]). The [empirical cdf] is a step function that shows the proportion of observed [data] points less than or equal to a specific value in the [data] . It creates a cumulative probability [distribution] directly from a vector say $\textbf{x}$ in the [data], without assuming a theoretical model therefore is the source of a many non-parametric procedures in statistics. Any [vector] $\textbf{x}$ in a [tabular data] set can have an [empirical cdf] but it is more difficult to justify it for unordered categorical variables since it implies an explicit order in $\textbf{x}$. For a given value $x_o$ in $\textbf{x}$ for any continuous or ordered categorical variable in the [data] the [empirical cdf], [ECDF] gives the percentage of [data] points in $\textbf{x}$ less than or equal $x_o$ for example, \#$[\textbf{x} \le x_o] \times \frac{1}{n}$. @fig-ECDF-continuous shows the ECDF curve of the [continuous variable] `rent` from the `rent99` data set.

```{r}
#| warning: false
#| label:  fig-ECDF-continuous
#| fig.cap: "The ECDF of a continuous variables. "
library(gamlss)
plot(ecdf(rent99$rent), main="ECDF", xlab="rent")
```

@fig-ECDF-ordered shows the ECDF curve of the oerdered categorical variable `location` from the `rent99` data set.

```{r}
#| fig-width: 5
#| label:  fig-ECDF-ordered
#| fig.cap: "The ECDF of an ordered categorical variables."
plot(ecdf(rent99$location), main="ECDF", xlab="rent")
```

The [empirical cdf] is also defined on the [residuals] of a fitted [model]. In [distributional regression] if the model represent correctly the [data generating mechanism] then the [residuals] of a [distributional regression] [model] should be behave as a [white noise]. In this case the empirical \[cumulative distribution\] function of the residuals should be very close to the \[cumulative distribution\] function of the Normal distribution. Next we fit a GAMLSS model using the `gamlss2()` function to the `rent99` [data]. We use the [formula] `rent~s(area)+s(yearc)+location+kitchen+kitchen` for the $\mu$ model and the [formula] `s(area)+s(yearc)` for $\sigma$ and we fit a \[BCT\]o distribution. The [ECDF] of the residual of the fitted [model] should behave, if the model is a [adequate fit] as normally distributed \[random\] variables. @fig-ECDF-resid_normal show the cdf of the [residuals] with a normal [cdf] superimposed in red. From the plot there is no reason he doubt the adequacy of the model. Note that the same information could be extracted by plotting the [QQ-plot] or the [worm plot] of the residuals.

```{r}
#| fig-width: 5
#| label:  fig-ECDF-resid_normal
#| fig.cap: "The ECDF of the residuals from a GAMLSS fitted model with the normal cdf superimposed."
#| warning: false
library(ggplot2)
library(gamlss.data)
library(gamlss2)
m1 <- gamlss2(rent~s(area)+s(yearc)+location+kitchen+kitchen|
                s(area)+s(yearc), family=BCTo, data=rent99 )
library(gamlss.ggplots)
gg <- resid_ecdf(m1)
gg+ggplot2::stat_function(fun = pNO, args=list(mu=0, sigma=1), col="red")
```

#### ECDF

See [Empirical cdf]

#### elliptical copulas

The [elliptical copulas] are based on the multivariate normal [distribution] and they can capture linear dependencies but no extreme tails

#### ensemble

A model [ensemble] is a method that combines [prediction]s from multiple [model]s to produce a single, usually more accurate and more robust, prediction. That is, instead of relying on one single [model], many [model]s are [fit] and their predictions are aggregated. The main motivation is that different [model]s are on their own more unstable and prone to errors while combining them could reduce the overall [error]. For example, given models $m_1, m_2, \ldots, m_M$, an ensemble produces

$$\hat{m} = \text{Aggregate}\big(m_1(x), \ldots, m_M(x)\big).$$

Aggregation for [regression analysis] [model] could be a simple or **weighted average** while for [classification model] could be **majority vote**. Different types of [aggregation rule]s are:

-   [bagging] which is [bootstrap] plus aggregation of the prediction which reduce variance e.g. \[random forest\]

-   [boosting] where [model]s where models are fit sequentially and each model focuses on previous [model] residuals a procedure which reduces [bias] and variance, e.g `AdaBoost`, [gradient boosting], `XGBoost`

-   [stacking] which combine different [model]s using simple or weighted averaging. In this case the combined [model]s are independently trained with no interaction between them.

#### empirical copulas

::: callout-note
Definition
:::

#### empirical risk

The [empirical risk] function is defined by dropping the expecations from the definition of the [risk] function, The definition of the [empirical risk] is given in [risk] as; $$\mathbb{ER}(g) = \frac{1}{n}\sum_{i=1}^n [ \ell oss(\hat{g}(x_i), y_i).$$ where $\ell oss()$ is the [loss] function.

#### entropy

The [entropy] for a discrete \[random\] variable $X$ is defined as: $$
\begin{split}
H(X) & = -\sum_{x \in X} p(x) \log p(x), \\
     &=  - E_p \log p(x) ,\\
     &= E_p \log \frac{1}{p(x)}
\end{split} $$\
That is, the [entropy] for a discrete random variables $X$ is equal to its expected value of minus the its log [probability]. Note that this quantity is identical to the [log likelihood] (but the [log likelihood] it is a function of the parameters and not the \[random\] variables $X$). The [entropy] of a continuous random variable $X$ is given as: $$\begin{split}
H(X) &=-\int_{X}f(x) \log f(x)  dx \\
      &= - E_f \log f(x)  \nonumber \\
     &= E_f \log \frac{1}{f(x)}  \nonumber 
\end{split} $$ The [entropy] is a [summary statistic] describing the randomness of the [distribution] of a \[random\] variables and it is a function of probabilities **not** the values or the [range] of the \[random\] variable $X$. The highest value of entropy is when we have equal probabilities for all values of $X$'s. That is when the $X$ has a [uniform distribution]. Note that the minus the log likelihood of a fitted [distributional regression] [model] which is defined as $- \ell(\boldsymbol{\theta})=\sum_{i=1}^{n} - \log f(y_i|\boldsymbol{\theta})$ is proportional to the empirical estimated of the entropy of the [response] variable with the constant of proportionately equal to $\frac{1}{n}$. This shows the close relationship between the concept of [entropy] and the concept of the [log likelihood] important for statistical [inference].

#### error

The term [error] of a [model] is the component which makes the model [stochastic], that is, it the model contains a set of [probability] elements. In [regression analysis] the [error] is often a terms used to describe the residual variation of a model.

#### errors

The term [errors] refers to the statistical part of a [stochastic] model which accounts for the natural variability of the data. The [errors] often refer to the [residuals] part of the [model] that is what is left after the model has been applied.

#### estimation

By [estimation] we mean the estimation of the [parameters] of the [model]. Estimation is achieved when the model is fitted to the [training] [data] using an [objective measure] of [goodness of fit]

#### estimator

An estimator is a function od the sample, a [statistic], that maps the data to a quantity intended to approximate an unknown parameter $\theta$.

#### estimate

An [estimate] is the numerical value obtained when using an [estimator] to obtain a parameter $\theta$ of a [model]. Let us assume that the [model] is specified by the [parameters] $\boldsymbol{\theta}$, After a [fit] we have [estimate]s for the $\boldsymbol{\theta}$ and we present them with a hat $\hat{\boldsymbol{\theta}}$.

#### exceedance probability

By [exceedance probability] we refer to the probably that a values of a \[random\] variable, $Y$, will exceed a certain pre specified value $c$, that is $Pr[Y \ge c]$ If we know the [cdf], $F(.)$ of the random variable $Y$ its [exceedance probability] is defined as $S(Y)=1-F(Y)$ where the function $S()$ often called in statistics the [survival function].

#### exceedance probability function

The [exceedance probability function] of a \[random\] variable $X$ is its [survival function] defined as one minus the [cdf] e.g. $EP(X)=S(X)=1-F(X)$.

#### explanatory variables

Explanatory variables in an [input-output model] are the input variables $X$. In a [regression analysis] are the variables in which affect the response. In a [distributional regression] are the variables on which the [distribution] of the response is conditioned on.Note that not all variables in the data need to be [explanatory variables] in a [model] only a relevant subset and [feature]s which are functions of the [explanatory variables].

#### exponential family

The [exponential family] is a family of theoretical [distribution]s with the propety of allowing [sufficient statistic]s

::: callout-note
We need a definition probably from book 2
:::

#### expected value

The [expected value] (the [mean] or first [moment]) of a [distribution] is defined as $\mathbb{E}(Y)=\int Y f(Y)dY$ for [continuous distribution]s and $\mathbb{E}(Y)=\sum Y f(Y=y)$ for [discrete distribution]s where the ingration of summetion, repsectively, is over the [range] of the \[random\] variables $Y$.

#### extreme value copulas

::: callout-note
we need a definition
:::

################################################################################ 

::: page-break
:::

## F

#### factor

A [factor] is a [categorical variable] in the [data]/[sample]. A [factor] is a [vector] column in the [data] set which takes only limited values which are called the [level]s of the [factor]. The [level]s can be **unordered** or **orderer**.

The function `str()` in `R` show the type of [vector]s in the [data].

```{r}
str(rent99)
```

while the function `levels()` show the levels of the [factor] `qrt`:

```{r}
levels(rent99$location)
```

A factor is represened in the design matrix of a model as a set of [dummy vectors].

#### fit

By [fit] we mean fitting a [model] to the [data] by minimise a [measure] of [goodness of fit] in order to select appropriate values for the [parameters] of the model. As a final results of the [fit] we have [estimator]s for the [parameters]. A single [fit] could provides unique [fitted values] and [residuals] for both [training] and [test] data sets.

#### fitted values

In [distributional regression] we use the expression [fitted values] to indicate estimates for the [distribution parameters] $\boldsymbol{\theta}$. In each fitted model there are as many [vector]s (of length $n$) of \[fitted parameters\] as the number of the assumed [distribution parameters].

To extract in `R` the fitted values of a fitted `gamlss2` model use;

```{r}
head(fitted(m1))
```

By default `head()` give only the first 6 values of the $n$ length vectors. Note that the resulted vectors are in the scale of the 'predictors' not the original [parameters]. Similar result can be obtain using function `predic(., type="link)`

```{r}
head(predict(m1,  type="link"))
```

#### fitted model

A [fitted model] is a model in which its parameters are estimaed using the data. Seee also [model fitting]

#### feature

A [feature] in [data] analysis is an one of the [explanatory variables] used for the model possible after a [transformation]. In statistical modelling a [feature] is a function of the [explanatory variables] in the [data].

#### function

There are several occasions we use the terms [function] in [statistical modelling]. In an [input-output model] we refer to the function $g()$ as an true unknown relationship between $X$ and $Y$ which the [model] tries to approximate. In the definition of distributions we use the functions $f()$ and $F()$ to describe [pdf]'s and [cdf]'s respectively. In [distributional regression] we use $D()$ for the [pdf] of the response. In [GLM]'s [GAM]'s and [GAMLSS]'s we use $g()$ to describe a [link function] a function which relates of the [distribution parameters] i.e. $\mu$ to the [predictor] of the parameter i.e. $\eta_{\mu}=g(\mu)$.

#### final model

Is the [model] chosen after a [model selection] is applied. In general we would like the [final model] to be an [adequate model]. That is, a [model] represending the [data] well and cable to answering the [questions] in hand.

#### finite mixture

A finite mixture is a [distribution] [pdf] make up as a sum of $K$ different distributions functions $f_k(x)$.

$$
f(x) = \sum_{k=1}^{K} \pi_k f_k(x),
$$ where: $f_k(x)$ are probability density [pdf]s functions, $\pi_k$ are mixing weights which should sum up to one, $\sum_{k=1}^{K} \pi_k = 1$. A [finite mixture] [distribution] is useful in [distributional regression] when the [response] show multi-modality. That is, when there are different [mode]s peaks in the response.

#### first order interaction

::: callout-note
We need a definition
:::

#### Frank copula

::: callout-note
We need a definition
:::

#### formula

The term [formula] and formulae refer to the `R` [formula] e.g. `y ~ x1 + x2` which is used in the definition of [model]s like [GLM]. The [formula] is a symbolic model language, not arithmetic where the idea behind is based on the @WilkinsonRogers73 paper which introduced it as a symbolic language to describe linear and ANOVA models. In in particular:

-   main effects

-   [interactions] and

-   nesting

For example in the [formula] , `rent~area+yearc+area:yearc`, the variable before $\sim$, `rent`, is the [response] variable. The second part of the formula `area+yearc+area:yearc` represent additive main effect for `area` and `yearc` and first order interaction for `area` and `yearc`. That is, everything after $\sim$ specifies how [explanatory variables] enter in the [model]. Note that for a [distributional regression] there could be more than one formulae, one for each of the [parameters] of the [distribution]. The wide use of [formula] is because [formula] matches statistical thinking, separates model specification from estimation, can be extended easily and works across different classes of models. The following symbols are used in an `R` formula.

| symbol  | meaning                               |
|---------|:--------------------------------------|
| $\sim$  | is modelled as                        |
| \+      | include term                          |
| :       | interaction between two or more terms |
| \*      | main effects plus interactions        |
| -1 or 0 | remove intercept                      |
| /       | nesting                               |
| \^      | interaction order                     |

: Symbols used in a formula

A [formula] in `R`, builds: the design matrix (including [factor] coding into [dummy variables]), contrasts for [factor]s and [interactions].

################################################################################ 

::: page-break
:::

## G

#### GAIC

GAIC stand for the Generalised Akaike Criterion @Akaike83 defined as `deviance` $+ K \times df$ where $df$ are the `degrees of freedom` and $K$ stands for the `penalty`.

#### GLM

GLM stands for Generalized Linear Model, @NelderWeddeburn72, a [mathematical model] which kick started the basic ideas of [statistical modelling] and dominated regression analysis in the 1980's. As [input-output model] it can be written as $$
X  {\longrightarrow} \fbox{g()}  {\longrightarrow} \mathbb{E}(Y) 
$$ where $\mathbb{E}(Y)$ is the expected values of the output $Y$ and $g()$ a known function connecting a linear function of the $X$'s, $\eta$, to the expected value of $Y$. As a [statistical model] a GLM can be written as; $$
\begin{split}
y  &  \stackrel{\small{ind}}{\sim } \mathcal{E}( \boldsymbol{\mu}, {\phi}) \nonumber \\
g_1(\boldsymbol{\mu}) &=  \eta = \textbf{X} \boldsymbol{\beta} \nonumber \\
 \end{split}
$$ {#eq-glm} where $\stackrel{\small{ind}}{\sim}$ is read as the vector of the response is "independently distributed \[random\] [vector] having a [distribution] belonging the [exponential family] $\mathcal{E}()$. The [exponential family] family has several distribution as sub-models: the [normal distribution], the [gamma distribution], the [inverse Gaussian distribution] for modelling continuous responses and the [Poisson distribution] and the [binomial distribution] for modelling discrete response. The fact that the elements of the vector $\textbf{y}$ are independent has the consequence that the [log likelihood] which is used as a [measure of goodness of fit] in GLM's is simply the sum of the individual log-[likelihood]s. Note that, within the [exponential family], the parameter $\mu$ is the expected values of the response e.g. $\mathbb{E}(Y)=\mu$. The second parameter $\phi$ is a [scale parameter] is not modelled in GLM's as a function of explanatory variables. The function $g()$ is called the [link function] and ensures that the [distribution parameter] $\mu$ is defined in the correct [range].

There were two major problems with the assumption for $g(\boldsymbol{\eta})$

#### GAM

GAM stands for Generalized Additive Model, @HastieTibshirani90, ...

$$
\begin{split}
y| \boldsymbol{\gamma}   &  \stackrel{\small{ind}}{\sim } \mathcal{E}( \boldsymbol{\mu}, {\phi}) \nonumber \\
g_1(\boldsymbol{\mu}) &= \textbf{X} \boldsymbol{\beta}+ s_{\mu,1}(\textbf{x}_{\mu,1})+\ldots+ s_{\mu, J_k} (\textbf{x}_{\theta,J_{\mu}}) \nonumber \\
 \end{split}
$$ {#eq-gam}

#### gamma distribution

#### GAMLSS

GAMLSS stand for Genaralized Additive Model for Location, Scaler and Shape, @RigbyStasinopoulos05. The classical GAMLSS model as first defined by @RigbyStasinopoulos05; $$
\begin{split}
y| \boldsymbol{\gamma}     &  \stackrel{\small{ind}}{\sim } \mathcal{D}( \boldsymbol{\theta}_1, \ldots, \boldsymbol{\theta}_k) \nonumber \\
g_1(\boldsymbol{\theta}_1) &= \textbf{X}_1 \boldsymbol{\beta}_1+ s_{\theta_1,1}(\textbf{x}_{\theta_1,1})+\ldots+ s_{\theta_1, J_k} (\textbf{x}_{\theta_1,J_{\theta_1}}) \nonumber \\
 \cdots &= \cdots \nonumber\\
g_k(\boldsymbol{\theta}_K) &= \textbf{X}_K \boldsymbol{\beta}_K + 
s_{\theta_K,1}(\textbf{x}_{\theta_K,1})+\ldots+ s_{\theta_K, J_K} (\textbf{x}_{\theta_K,J_{\theta_K}})
\nonumber 
 \end{split}
$$ {#eq-gamlssclassical} where we assume that the response variable $y_i$ for $i=1,\ldots, n$, is independently distributed having a [distribution] $\mathcal{D}( \theta_1, \ldots, \theta_k)$ with $k$ parameters and where $s_{\theta_k, j} (.)$ for $k=1,\ldots,K$ and $j=1,\ldots, J_{\theta_k}$ are smoothers for different explanatory variables. Note that smoother are depending on smoother parameters $\lambda$. Because of the duality of smoothers and random effects it was soon realise that the model can be a written in its **mixed** random effect model form as:

$$
\begin{split}
y| \boldsymbol{\gamma}   &  \stackrel{\small{ind}}{\sim }  \mathcal{D}( \boldsymbol{\theta}_1, \ldots, \boldsymbol{\theta}_k) \nonumber \\
g_1(\boldsymbol{\theta}_1) &= \textbf{X}_1 \boldsymbol{\beta}_1+ \textbf{Z}_{1,1} \boldsymbol{\gamma}_{1,1}+ \dots +\textbf{Z}_{K, J_1} \boldsymbol{\gamma}_{K, J_1} \nonumber \\
 \cdots  &= \cdots \nonumber\\
g_k(\boldsymbol{\theta}_K) &= \textbf{X}_K \boldsymbol{\beta}_K + \textbf{Z}_{K,1} \boldsymbol{\gamma}_{K,1}+\dots+\textbf{Z}_{K,1} \boldsymbol{\gamma}_{K,J_K}  \nonumber
 \end{split}
$$ {#eq-gamlssmixed} where $\boldsymbol{\gamma}_{k,j}$ are random effect, for $k=1, \ldots,K$ and $j=1,\ldots,J_K$ and where each $\boldsymbol{\gamma}_{k,j}$ is distributed as a Normally distributed variable with zero mean and standard deviation given by $\sigma_{b_{k,j}}$. In fact there is set of $\sigma_{b_{k,j}}$'s which length is the length of all smoothers in the model. Note that smoothing parameters $\lambda_{\theta_k, j}$ and standard errors $\sigma_{b_{k,j}}$ are inverse related $\lambda_{k, j}=\frac{1}{\sigma_{b_{k,j}}}.$

#### `gamlss` {#gamlss-1}

`gamlss` is the original package in `R` for fitting a GAMLSS model @StasinopoulosRigby07.

#### `gamlss2`

`gamlss2` the new package in R for fitting a GAMLSS model.

#### `gamlss.data`

`gamlss.data` is a package in `R` containing data sets use to demonstrate GAMLSS models.

#### `gamlss.prepdata`

`gamlss.prepdata` is a package in R to help users to preper data for analysis using a [distributional regression] model.

#### `gamlss.ggplots`

`gamlss.ggplots` is a package in `R` to help with [diagnostics] and other graphics using the `ggplot2` package. The functions in the package can be applied to fitted GAMLSS model independently whether were fitted using the [`gamlss`](#gamlss-1) or [`gamlss2`].

#### `gamlss.dist`

`gamlss.dist` a package containing all the theoretical [distribution] which can be assumed for the response when fitting a GAMLSS model.

#### `gamlss.tr`

`gamlss.tr` can take any [distribution] family in `gamlss.dist` and truncated `left` `right` of in `both` directions.

#### `gamlss.cens`

`gamlss.cens` can take any [distribution] family in `gamlss.dist` and apply `left` `right` or `interval` censoring.

#### Gaussian white noise

An identical distributed standardised normal \[random\] variable with no pattern, see [white noise] see [white noise].

```{r}
#| fig-width: 5
#| label: fig-gaussianwhitenoise
#| fig-cap: "Gaussian white noise of 1000 observations"
y <- rnorm(1000)
plot(y)
```

A [worm plot] of a [Gaussian white noise] should show no pattern:

```{r}
#| fig-width: 5
#| label: fig-wpgaussianwhitenoise
#| fig-cap: "A worm Gaussian white noise of 1000 observations"
library(gamlss)
wp(resid=y)
```

#### generalized Tobit model

::: callout-note
We need a definition probably from book 2
:::

#### generalized Tobit distribution

::: callout-note
We need a definition probably from book 2
:::

#### goodness of fit

A [goodness of fit] [measure] is a type of distance measuring how far is the [model] to the [data].

#### GAIC

GAIC is the Generalise Akaike Information Criterion defined as `deviance` $+k \times df$ where $k$ is the penalty applied to the [degrees of freedom] $df$.

#### graphic

A [graphic] is a plot which help the analysis of [data]. A post-[fit] graphic that is a plot depending on the [fitted values] of a [model] usually is either [diagnostics] to help checking assumptions or it is there to help the [interpretation] of the model.

#### gradient boosting

::: callout-note
We need a definition probably from book 3
:::

#### Gumbel copula

For \[random\] variables $U_1$ and $U_2$ with [range] in $(0,1)$ and parameter $\theta \ge 1$ the [Gumbel copula] is defined as

$$C_\theta(U_1,U_2)
=
\exp\!\left(
-\Big[(-\log U_1)^\theta + (-\log U_2)^\theta\Big]^{1/\theta}
\right)$$ The [Gumbel copula] belong to the \[Archimedean copula\] family. It can model only positive dependence only and only the upper tail. It can not model the lower tail dependence. It is asymmetric stronger in upper tail. If the parameter $\theta = 1$ implies independence. Large $\theta$ implies stronger dependence and $\theta \to \infty$ implies comonotonicity. The relationship of $\theta$ with Kendall’s $\tau$ is:

$\tau = 1 - \frac{1}{\theta}
\quad \Rightarrow \quad
\theta = \frac{1}{1-\tau}$ The [Gumbel copula] supports strong upper tails and its useful for modelling extremes high values cluster. The upper tail dependence coefficient is: $\lambda_U = 2 - 2^{1/\theta}$ ans the ;ower tail dependence is: $\lambda_L = 0$. The [Gumbel copula] should be use if: i) joint large outcomes are important, ii) dependence increases in the upper tail, or the work involves extreme rainfall / floods, financial booms, large insurance claims.

################################################################################ 

::: page-break
:::

## H

#### hazard function

The [hazard function] of a \[random\] variable $Y$, $h()$, shows the risk of the instantaneous failure of $Y$. It is defined as the [pdf] divided by the [survival function] i.e. $h(Y)= \frac{f(y)}{S(Y)}=\frac{f(y)}{1-F(Y)}.$

```{r}
library(gamlss.dist)
gen.hazard("BCTo", mu=1, sigma=0.2, nu=1, tau=10)
curve(hBCTo, from=0.001, to=10)
```

Or using `ggplot2`;

```{r}
 library(ggplot2)
 ggplot(data.frame(x = c(0.001, 10)), aes(x)) +
   stat_function(fun = hBCTo) +
   labs(x = "x", y = "S(x)")
```

#### histogram

A [histogram] is a estimated density probability function function for a [sample] [vector]. See [density function] for a [smooth function] of a [histogram].

```{r}
library(MASS)
truehist(rent99$rent)
```

#### hierarchical Archimedean copulas

::: callout-note
We need a definition
:::

#### hypothesis

The hypothesis is what the researcher tries to understand and answer see also the `purpose` of the study

#### hypothesis test

::: callout-note
We need a definition
:::

#### hyper parameter

################################################################################ 
::: page-break
:::

## I

#### independence

The word [independence] is refereeing to the state of two or more \[random\] variables. For example two random variance $Y_1$ and $Y_2$ are independent if their joint density [probability] can be written as the product of their marginal; $f(Y_1, Y_2)= f(Y_1) \times f(Y_2)$. In the same way if the probability of more than two random variables can be written as the product of their marginals then then the \[random\] variables are independent.

#### information

The word [information] represent the uncertainty about an unknown quantity, in our case the [data]. In [statistical modelling] is refereed to the way [information] is extracted from [data] using a [model].

#### information criterion

By [information criterion] we refer to a [measure of goodness of fit] which it based on [information theory].

#### information theory

By [information theory] we mean the theory of of communication developed by @shannon1948mathematical which is based on the idea of [entropy].

#### inter quantile range

::: callout-note
We need a definition probably from book 2
:::

#### interpretable model

A model is an [interpretable model] if its is easy to explain to others. Most [mathematical model]s but not all [algorithmic model]s are [interpretable model]s. The following words have the same meaning as [interpretable model], **transparent** model, **explainable** model or **comprehensive** model.

#### interval values

A \[random\] variable is taking [interval values] if its exact value observed value is not known but we know that it occurred in a specific interval [range] i.e $10< Y <15$. Another expression of this behaviour is [censored values].

#### inverse Gaussian distribution

::: callout-note
We need a definition
:::

#### input-output model

An input-output model is a model where the variables $X$, the input, affect the variables $Y$, the output i.e. $X \rightarrow Y$. Input-output model are [supervised learning model]s since the [response]/\[targer\] variable, $Y$, always exist. @breiman2003statistical use the diagram $$
X  {\longrightarrow}  \fbox{NATURE} {\longrightarrow} Y, \ 
$$ to describe an [input-output model]. The problem is that nature is too complex so we use a [model] to approximate nature and how is working. $$
X  {\longrightarrow}  \fbox{Model} {\longrightarrow} Y \
$$ In practice the [model] is a mathematical function ot the type, $Y=g(X)$, describing the relationship between $X$ and $Y$. $$
X  {\longrightarrow} \fbox{g()}  {\longrightarrow} Y \ 
$$ The function $g(.)$ is an unknown function so the task of the modeller is to estimate it. In [regression analysis] we assume that the model is a [stochastic model] and has the form $Y=g(X)+\epsilon$, where, the [error] term $\epsilon$ is the **stochastic** components of the model and the unknown function $g()$ is the **mathematical** component. Now the [input-output model] can be written as: $$
X  {\longrightarrow} \fbox{g()}  {\longrightarrow}  \mathbb{E}(Y) \ 
$$ here $\mathbb{E}(Y)$ is the expected value (the [mean]) of the output $Y$.

In a [distributional regression] framework the representation is more complex. The unknown function called here $G()$ relates all the parameters $\boldsymbol{\theta}=(\theta_1, \ldots, \theta_k)$ of the distribution, $f(y|\boldsymbol{\theta})$, of the [response] to the explanatory variable. e.g. $\boldsymbol{\theta}=G(X)$. The [input-output model] in this case can be can be written as: $$
X  {\longrightarrow} \fbox{G()}  {\longrightarrow} f(Y|\boldsymbol{\theta}) \ 
$$ where $f()$ is the [pdf] of the output $Y$ which has parameters $\boldsymbol{\theta}$ and which all the parameters are function of the input, $G(X)$. The main difference between the [regression analysis] of model $Y=g(X)+\epsilon$ and the [distributional regression], is that the first produce a single fitted value $\hat{y}$, an estimate of the mean while the second produce a fitted distribution $f(Y|\hat{\boldsymbol{\theta}})$ which shape is allowed to vary according to the values of the input variable $X$.

#### independent random variable

A [vector] of [random variable]s say $\textbf{y}$ is said to be independent (or independently distributed) if the [distribution] of the component of the vector can be written as the product of the individual probabilities i.e. $Pr(\textbf{y}) =  \prod_{i=1}^n Pr({y}_i)$

#### independent variables

In a [regression analysis] the [explanatory variables], [feature]s or  input} are also called the [independent variables]



#### interaction

In statistics an [interaction] is the effect that one or more [explanatory variables] have on the [predictor]. When we believe say that $x_1$ and $x_2$ simultaneously effecting the predictor we say that $x_1$ and $x_2$ **interact** with each other. In linear and generalised linear models (LM and GLM) linear [interaction]s are ecy to obtain but they have to be declared explicitly in the [model]. The terms in LM and GLM models couls be:

-   **main effects** e.g. `~x1+x2+x3`,

-   **first order** interactions e.g. `~x1*x2`

-   **second order** interactions e.g. `~x2*x2*x3`

-   e.t.c.

Two obtain the [interaction] of two [continuous variable]s just multiply the two variables together to get their product as a new [feature]/[term] in the design matrix. For example, `x1*x2` in a formula is equivalent to multiplying the two [continuous variable]s together and obtain their product as the new term, so `I(x1*x2)` in a formula will be equivalent. Note that [categorical variable]s are represented in the design matrix of a [model] as dummy [vector]s.

#### interactions

By [interactions] within a [regression analysis] framework we refer to, how two or more [explanatory variables] effect the [response] and for [distributional regression] on how two or more [explanatory variables] effect the [distribution] of the [response]. In R formula [interactions] are denoted as `A:B` or \`A\*B= A+B+A:B. 


#### IQR

Please see [inter quantile range]

#### intercept

In any (linear) design matrix of a [model] the intercept represent the constant of the model. In [regression analysis] the constant is included in the model by default. So any [formula] will include the constant unless is taken out using in the formula using `-1`.

For example in the following code the [intercept] is included by default;

```{r}
library(gamlss)
data(rent99)
head(with(rent99,model.matrix(formula(~area+location))), 8)
```

while in the following code the [intercept] is excluded';

```{r}
library(gamlss2)
data(rent99)
head(with(rent99,model.matrix(formula(~area+location-1))), 8)
```

Note that [model]s fitted using the two design matrices above will have identical fits in the [predictor] and their [deviance].

```{r}
m_1 <- gamlss2(rent~area+location, data=rent99, family=NO)
m_2 <- gamlss2(rent~area+location-1, data=rent99, family=NO)
AIC(m_1, m_2, k=0)
```

```{r}
head(cbind(fitted(m_1), fitted(m_2)), 10)
```

The reason, is that both linear spaces generate by the two matrices are representing the same linear subspace for any linear fit will have identical `fitted values` but the [interpretation] of the [coefficients] of the [linear model] is different.

```{r}
m_1 <- gamlss(rent~area+location, data=rent99, family=NO)
m_2 <- gamlss(rent~area+location-1, data=rent99, family=NO)
AIC(m_1, m_2, k=0)
```

#### inference

In statistics [inference] refers to the idea that under certain circumstances we can go from the [sample]/[data] to draw conclusions about the [population] of interest, That is we can can go from the **small** to the the **big**. The circumstances depend on [assumptions] about the how the data were generated ([data generating mechanism]) .

```{mermaid}
%%| fig-width: 2
%%| label: fig-inference
%%| fig-cap: "We use the sample to go back to the population"
flowchart LR
P(population) --> G[data <br \> generating <br \> mechanism]
G --> D(sample/ <br \> data)
D --> M(model)
M --> |inference| P
```

#### interpretation

The interpretation of a model is the story behind the fitted model, what it is telling you and how to answer the [questions].

#### input variables

In an \[input output model\] the input or the [input variables] are the [explanatory variables] in a [regression analysis] same as the input in an [input-output model].

################################################################################ 
::: {.page-break}
:::

## J

#### joint distribution

::: callout-note
We need a definition
:::

################################################################################ 
::: {.page-break}
:::
## K

#### K-fold cross validation

A [K-fold cross validation] process provides [training] and [test] data for all the observations by going through a K-fold [data partition]. The [data] are shuffle and slit into K data sets of approximately equal sizes. Then data from the K-1-folds are use to [fit] the [model] and the remaining fold to evaluate the performance of the [model] e.g. getting prediction fitted values and test data residuals see @fig-k-fold. By the time the process is finish a [K-fold cross validation] provides unique [test] `fitted values` and [test] `residuals`. In addition provides multiple $K-1$ values from the fitted values and residuals obtained durring the [training] fits. Note that each fold is used once as [test] data while the [training] data uses k−1 folds. For a [final model] we can use the [test] fitted values and [test] residuals to check the overall performance of the model. Since all the measures to check the performance are obtain from test data over-fitting\] ca be laso checked.

The special cases of [K-fold cross validation] is when $K = n$ which implies that t there are $n$ model to be fitted is called [leave-one-out cross validation]. Stratified k-fold preserves class proportions

```{mermaid}
%%| fig-width: 2
%%| label: fig-k-fold
%%| fig-cap: "How k-fold cross validation is working: it utilised the data partition to create fitted values and residuals from the test data to create a model evaluation based only on test data"
flowchart LR
    D[Data] --> S[Shuffle <br/> & Split]

    S --> F1[fit folds 2...K]
    S --> F2[fit folds 1,3...K]
    S --> F3[...]
    S --> Fk[fits folds 1,...K-1]

    F1 --> T1[test fold 1]
    F2 --> T2[test fold 2]
    F3 --> T3[...]
    Fk --> Tk[test fold K]

    T1 --> R1[test fitted values & resid <br/>  from fold 1]
    T2 --> R2[test fitted values & resid <br/>  from fold  2]
    T3 --> R3[test fitted values & resid <br/> from fold  ...]
    Tk --> Rk[gest fitted values & resid <br/> from fold  K]

    R1 --> A[check <br/>  performance]
    R2 --> A
    R3 --> A
    Rk --> A
```

#### kurtosis

::: callout-note
We need a definition probebly from book 2
:::

#### kurtosis parameter

A kurtosis parameter is a {shape parameter\] of the [distribution] which effect how fat are the tails of the distribution.

################################################################################ 
::: {.page-break}
:::

## L

#### LASSO

::: callout-note
We need a definition
:::

#### least squares

The method of [least squares] is oldest method used to [fit] a \[regression model\].

::: callout-note
We need more here
:::

#### level

By [level]s we refer to the distinct values of a [factor].

#### learner

In [boosting] methodology a basic [learner] is a simple [model] with the property that for [prediction] purpose, it has to do a little bit better than the average prediction. The idea is that if we average a lot of **complementary** **sequential** [learner]s we would be able to produce an [adequate fit]. By complementary we mean [model]s each capturing a little different aspect of the [data]. By sequential we mean that each learner tries to improve from the the previous by weighting more \[observation\]s in the larger [residuals] in the previous [model].

#### leave-one-out cross validation

See [K-fold cross validation].

#### linear model

By linear model we refer to models described by the [assumptions] $\textbf{y}=\textbf{X}\boldsymbol{\beta}+e$ where $e_i \sim N(\boldsymbol{0}, \sigma^2)$. That is the relationship between the response and the explanatory variables is linear determined by the coefficients $\boldsymbol{\beta}$ and the error term has a normal [distribution] with constant variance $\sigma^2$. The unknwon parameters in this case are the $\boldsymbol{\beta}$ and $\sigma^2$. I we know those parameters we can predict the behaviour of the response if the model is correct.

::: callout-note
Do we need more?
:::

#### link function

A function connecting the model predictor with the [distribution parameter] for example $\eta_{\sigma}= g(\sigma)$ The link function ensure that the [distribution parameter] is on the right [range]. For example, since $\sigma$ take values in the positive real line $0< \sigma <- \infty$ modelling sigma as $\eta_{\sigma}=log(\sigma)$ will make sure that $\exp(\eta_{\sigma})$ is always positive. For modelling purposes the the link function $g(\theta)$ its inverse $g^{-1}(\eta_{\theta})$ and the first derivative $d \eta_{\theta}/d\theta$ must be defined.

#### likelihood

The likelihood function is define as the [probability] of observing the [sample] seeing not as a function of the random variable involed but as a function of the parameters of its distribution. For example, let the random vector variable $Y$ to come from an assumed [distribution] $f(\textbf{Y}|\boldsymbol{\theta})$. We obsrved the $n$ dimensional vector $\textbf{y}$. If in addition we assume that the elements of $\textbf{y}$ are independed fraom each other, then the likelihood funtion for $\boldsymbol{\theta}$ is defined as $$L(\boldsymbol{\theta})=\prod_{i=1}^{n} f(y_i|\boldsymbol{\theta})$$ and its log-likelihood as

$$\ell(\boldsymbol{\theta})=\sum_{i=1}^{n} \log f(y_i|\boldsymbol{\theta})$$ In both cases the functions are seen as functions of the parameters $\boldsymbol{\theta}$ rather than of the ranom variable $\textbf{y}$. Note also that the assumed [data generating mechanism] plays a role in the construction of the likelihood function. If we suspect that the data are not independent from each other the definition of the likelihood sgould be different.

#### likelihood ratio test

The [likelihood ratio test] is a way to compare two [nested models]. Let us have two fitted model $\hat{m}_1$ and $\hat{m}_2$ such as the model that $\hat{m}_1$ is *nested* in model $\hat{m}_2$, $\hat{m}_1 \in \hat{m}_2$, see [nested models], that is, $\hat{m}_1$ is special case of $\hat{m}_2$. Note that the idea of nested is easy to defined in [mathematical model]s but not in [algorithmic model]s. The null hypothesis is that $$H_0: m_1 \simeq m_2$$ that is the two model are similar, against

$$H_1: m_1 < m_2$$ that is, model $m_2$ is better than $m_1$. let \ell\_0 the maximised log-likelihood under $H_0$ and \ell\_1 = maximised log-likelihood under $H_1$ the [likelihood ratio test] is defined as

$$\Lambda = -2(\ell_0 - \ell_1)$$ the [deviance] deference between the two models. Under regularity conditions and large samples: $\Lambda \;\sim\; \chi^2_{\,df_a}$ where $df_a = \text{number of additional degrees of freedom in } H_1$. To test the $H_0$

-   Compute $\Lambda$ and the difference in $df$'s.

-   Compute p-value: $p = P(\chi^2_{df} \ge \Lambda)$

-   Reject $H_0$ if $p < \alpha$ where $\alpha$ is usulaly taked as $0.05$.

Here we use the `rent99` data set. As an example of the use of the [likelihood ratio test] we are testing the null, $H_0$, hypothesis on whether we should include a linear term or the alternative, $H_1$, on whether we should include a non-linear smooth tern for `area`. The model fits a `BCTo` distributions and all other terms are fitted identically so the `m1` model is nested into the `m2` model.

```{r}
m1 <- gamlss2(rent~area+s(yearc)+location+kitchen+
                cheating+bath, data=rent99, family=BCTo)
m2 <- gamlss2(rent~s(area)+s(yearc)+location+kitchen+
                cheating+bath, data=rent99, family=BCTo)
deviance(m1)-deviance(m2) 
m2$df - m1$df
```

The resulted [likelihood ratio test] is `r round(deviance(m1)-deviance(m2), 2)` with `r round(m2$df - m1$df, 2)` degrees of freedom difference. Alternatively we can use the function `LR.test()` to do the test;

```{r}
source("~/Dropbox/github/gamlss/R/LR-test-12-06-2013.R")
LR.test(m1,m2)
```

The resulting p-value is very small so we accept the alternative that that the smooth non-parametric terms is need for `area`.

#### log likelihood

The [log likelihood] is a [objective measure] of goodness of fit for a [model]. It is denoted as $\ell(\boldsymbol{\theta})$ see [likelihood] for its definition. Note that in general most of [objective measure] of goodness of fit depend on the [data generating mechanism] so [log likelihood].

#### location parameter

A parameter of the [distribution] describing the centre of the [distribution]. The most common [location parameter]s are the [mean] and the [median].

#### loss

A [loss] function is a [objective measure] of goodness of fit. The [loss] function $\ell oss()$ is a function of both the [data] and the fitted [model] and measures how far we are prepared to accept that the model is correct. In gambling the [loss] function has a monetary value but in [statistical modelling] is a measure of difference between the [model] and the [data], (see also [risk]). Typical loss functions are; i) \[squared errors\] i.e. $\sum_{i}^n (y_i - \hat{y_i})^2$ and \[absolute errors\] i.e. $\sum_{i}^n \left|y_i - \hat{y_i} \right|$ determine how far the actual value $y$ is from its estimating value $\hat{y}$. Note that in [distributional regression] $\hat{y}$ is an estimate of the [location parameter] of the the model therefore is not an appropriate measure we are interest in other parts of the [distribution] fo the [response] for example the [tail]. a more appropriate [objective measure] in this case could be minus the [log likelihood] $-\ell(\hat{\boldsymbol{\theta}}_i)$. Notice that [loss] functions could include penalty terms penalising the complexity of the model.

#### lower model

The [lower model] is the simplest possible model in the range of all possible models to be selected in a [step wise] procedure. Often it is the [null model].

################################################################################ 
::: {.page-break}
:::

## M

#### measure

A [measure] in [regression analysis] is an [objective measure] which is used either as a [measure of goodness of fit] or a way to evaluate the [model].

#### main effect

::: callout-note
We need a definition
:::

#### Markov Chain Monte Carlo

[Markov Chain Monte Carlo], [MCMC], are a class of algorithms for sampling from complex probability distributions, especially Bayesian posterior distributions.

#### MCMC

MCMC stands for \[Markov cChain Monte Carlo\] — a class of [algorithm]s for sampling from complex probability distributions, especially [Bayesian] posterior distributions.

#### marginal distribution

::: callout-note
We need a definition
:::

#### mathematical model

A [mathematical model] is a [model] which is build using mathematical equations.

#### MLE

see [maximum likelihood estimation]

#### maximum likelihood estimation

The Maximum Likelihood Estimation, MLE, is method of fiting a [distribution] to a vector $\textbf{y}$ using minus the [log likelihood] as [objective measure] of goodness of fit. Note the minimise $-\ell(\boldsymbol{\theta})$ is equivalent of ninimise the [deviance] $-2\ell(\boldsymbol{\theta})$ or maximising the [likelihood] $L(\boldsymbol{\theta})$ or the [log likelihood], $\ell(\boldsymbol{\theta})$.

#### measure of association

A [measure of association] is a [statistic] describing the pairwise connection between variables in a the [data]. Note that there are differnt types of [measure of association] dependenting on the type of the \[vecror\]s involve. For exaple association between

-   **continuous** against **continuous** variables

-   **continuous** variable against **categorical** variable

-   **categorical** variable against **categorical** variable

```{r}
#| fig-width: 5
#| label: fig-association
#| fig-cap: "Poirwise measures of association in the Munich `rent99` data set." 
library(gamlss.prepdata)
data_association(da, method = "circle")
```

#### measure of goodness of fit

A \[measure of goodness\] of fit is a way to evaluate the fidelity of the data for a given. model. That is, how close, is the model to the data using an [objective measure] of goodness of fit. See also [objective measure]

#### mean

A [mean] is defined either as one of the [characteristics of the distribution] of a \[random\] variable or as a characteristic of a [vector] in the [data] set. The mean of a [vector] in the [data] is the average value of the [vector] i.e. $\bar{x}= \frac{1}{n}\sum_{i=1}^n x_i.$ The mean or [expected value] of a [distribution] sometimes called the first [moment] of the [distribution] is defined as $\mathbb{E}(Y)=\int_{-\infty}^{\infty} Y f(Y)dY$ for a [continuous distribution] and as $\mathbb{E}(Y) = \sum_{i=1}^{\infty} Y_i f(Y_i)$ for a [discrete distribution].

#### median

A [median] is defined either as one of the [characteristics of the distribution] of a \[random\] variable or as a characteristic of a [vector] in the [data] set. Let $F(Y)$ be the [cdf] of the random variable $Y$ then the [median] of $Y$ is defined as the value of $Y$ satisfying the equation $0.50=F(Y)$ or $\text{median}(Y)=F^{-1}(0.50)$ where $F^{-1}()$ is the inverse of the [cdf] also known as the [quantile function]. For [vector] in the [data]/[sample] the median can be defined similarly using the [empirical cdf] of the [vector].

#### missing observartions

The idea of \[missing observations\] are [data] points that were intended to be recorded but have no observed value for one or more of the [vector]s of variables. The [data generating mechanism] on how the \[\[missing observations\] were generated it matters for [model] analysis:

-   MCAR – **Missing Completely At Random**; The mechanism of the missing observations is unrelated to any data (observed or unobserved). The complete-case analysis is unbiased but inefficient.

-   MAR – **Missing At Random**; the mechanism of the missing observations depends only on the observed variables Likelihood so methods based on multiple imputation are valid.

-   MNAR - **Missing Not At Random**. The missing mechanism depends on the unobserved values themselves. This type of missing values need and explicit modelling of the mossing mechanism or **sensitivity** analysis.

The consequences of missing values are a loss of [information] and \[power\], potential [bias] in estimates and complications in model fitting and interpretation

For more information about the handing of missing values within [distributional regression] we commenter the book @van2018flexible.

#### mode

A [mode] is defined either as one of the [characteristics of the distribution] of a \[random\] variable or as a characteristic of a [vector] in the [data] set. The [mode] as one of the [characteristics of the distribution] indicates which the value of a \[random\] variable $X$ in which it has its higher [pdf] value. In a [vector]s in the [data], $\textbf{x}$, the [mode] indicates the value of $\textbf{x}$ with the highest frequency of occurring.

#### moment

::: callout-note
We need a definition probably from book 2
:::

#### mixed distribution

::: callout-note
We need a definition probably from book 2
:::

#### mathematical model

A mathematical model is a model which is using mathematical equations to describe the variables involved. A popular mathematical model partial or ordinary differential equations model

#### machine learning

Machine learning refers to a selection of algorithmic models. Some of the machine learning are [model]s are \[supevised learnig\] models i.e [regression] type and some \[classification\] type. A typical [regression] [machine learning] [model] has the form $\textbf{y}=g(\textbf{x})+\boldsymbol{\epsilon}$ where the error $\boldsymbol{\epsilon}$, a [vector], is assumed to be an independently distributed \[random\] variable and $g()$ an unkown function to be estimated form the data. Note that one of the implicit [assumptions] of the model is that the [error], $\boldsymbol{\epsilon}$, has a symmetric distribution. This explicit assumption can be recrtified by using a [transformation] on $\textbf{y}$ which would possible make the transformed response $\textbf{y}'$ symmetric before fitting. Note however that this transformation is not always exist therefore [distributional regression] models do not rely on it but relying on the fact that the a theoerical [distribution] of the [response] exist.

#### MSE

The term stands for Mean Square Error. Its defined as $$\text{MSE} = \frac{1}{n}\sum_{i=1}^n (y_i - \hat{y}_i)^2$$ and it is an [empirical risk] and a [objective measure] of goodness of fit for the standard [regression analysis] [model]s. It can be calculated in both [training] or [test] data sets for a [objective measure] of goodness of fit or a measure of [prediction] power, respectively. MSE is **NOT** appropriate for [distributional regression] models unless the [purpose] of the study is on the centre of he assumed distributions.

#### MAE

The term {MAE} stands for Mean Absolute Error. It is defined as $$\text{MAE} = \frac{1}{n}\sum_{i=1}^n |y_i - \hat{y}_i|$$ and it is an [empirical risk] and a [objective measure] of goodness of fit for the standard [regression analysis] [model]s. It can be calculated in both [training] or [test] data sets for a [objective measure] of goodness of fit\] or measure of [prediction] power, respectively. MAE is **NOT** appropriate for [distributional regression] models unless the [purpose] of the study is on the centre of he assumed distributions.

#### model

A [model] is a simplification of reality to provide simple way to understand the structure of a problem. There are different types of [model]s according to [purpose] of the study. The [purpose] of the study is defined by the [questions] the investigator who contact the study need to answer. In [data analysis] we can think of a [model] as a filter which tries to extract the important information from the data while disregard the non-relevant see @fig-filter.

```{mermaid}
%%| fig-width: 2
%%| label: fig-filter
%%| fig-cap: "The model acts as filter to extract  important information  from the data."
flowchart LR
    direction LR
    D[data]
    F[model ]
    I(information)
  D --> F
  F --> I
```

In [data analysis], often, there are basic [subjects] of interest and there [variables] which affect the subject behaviour. Any study would trying to understand the behaviour of the [subjects] at different values of the [variables].

-   A [mathematical model] tries to answer the [questions] of the [study] using mathematical equations.

-   An [algorithmic model] is using algorithms that is a set of programmable rules to answer the [questions].

Another important distinction between models is;

-   A [top down model] in which the [variables] influence is applied to all the subjects. That is, there isa **macro** influence of the [variables] applying to all [subjects]. Typically a [regression analysis] model is a [top down model].

-   A [bottom up model] in which the **micro** behaviour of the objects affect the overall global behaviour of the variables. A typical example of this type of [model] is the [agent based model] whete the individual behaviour of the [agent] affect the overall behaviour. A [agent based model] is a [simulation model] where the behaviout of variables is examing after the simulation of the model several times.

A [data partition based model] is a [model] which assumes that different [variables] in the data affect the [subjects] differently at different parts of the [data].

An [adequate model] is a [model] which fits the [training] data well after [diagnostics] checks and its [interpretation] will help to answer the [questions], but remember that;

> `all models are wrong but some are useful`.
>
> -- George Box (@box1979robustness)

Whether a model is useful depends on the [purpose] and whether could answer the [questions] of the study.

#### model average

The terms [model average], [model aggregation] and [stacking] are almost synonymous and indicate that the [final model] is chosen by type of averaging between different [fit]ted [model]s. This is in compaction for choosing a single [model] and is a way of summarizing the results from multiple fitted models. The [model average] couls be advantageous if the fitted models complement each other. For example, in a [distributional regression] framework, this could mean that one model fit the [tail] of the [distribution] better while the other fits the middle of the data in the response better. By averaging the [model]s well we could possible fit both the middle and the [tail] well. There are a lot different techniques to average [model]s. In [distributional regression] a possibility is a [finite mixture] [distribution] with elements all the fitted distributions. For example $$ f_F(y_i)= \sum_{i=k}^{K} f_k(y_i| \hat{\boldsymbol{\theta}}^{k}_{i}) $$ where $i=1,2,\ldots, n$ and we assumed K different [model]s with assumed distributions $f(|\boldsymbol{\theta}^{k})$.

#### model aggregation

see [model average]

#### model comparison

By [model comparison] we mean the act of comparing between two or more fitted models in order to chose between then. This comparison can be done by using;

i)  a [likelihood ratio test].

ii) an [objective measure] of [goodness of fit]

iii) [diagnostics].

Note that only two [nested models] can be compared with the [likelihood ratio test] and that the comparison is done on the [training] [data]. For [objective measure] and [diagnostics] the comparison can be done in both the [training] or [test] [data] sets.

#### model fitting

A [model fitting] process involves the [data], the [model] (which depends on [assumptions]) and the [purpose] of the study. The assumed [model] is fitted to the [data] by minimise an [objective measure] which should depend on the [purpose]. @fig-fit shows a single [fit] to the [data] which should reflect the [purpose] of the study. Note that we will need a [model selection] procedure to make sure that we end up with an [adequate fit]. A [adequate fit] provides evidence that we have not [under fit] but we could have [over fit]. Over fit could be checked with [test] data. A single [fit] provides unique [fitted values] and [residuals] for both [training] and [test] data sets.

```{mermaid}
%%| fig-width: 2
%%| label: fig-fit
%%| fig-cap: "The model fitting process needs both data and model which to conform with the purpose of the study  "
flowchart LR
  subgraph model-fitting-process
   style model-fitting-process fill:#e3f2fd,stroke:#1e88e5,stroke-width:2px
    direction LR
    D[data]
    M[model]
    P[purpose]
  end
  D <--> M
  P <--> D
  M <--> P
  P --> Q
  M --> F(fit)
Q[objective measure] <--> F
```

#### model formula

A model formula in R takes

::: callout-note
We need a definition
:::

#### model selection

A [model selection] is a procedure to select a [final model] (hopefully an [adequate model] to answer  the [questions] in the [data]) from  a set of different [candidate model]s. 


The [model selection] in a GAMLSS framework has two tasks: 


i) to choose the [distribution] of the [response] and 

ii) and to find **which** [explanatory variables] and **how** they affects the [distribution] of the [response]. 

In a GAMLSS [model] the [distribution] of the [response]  is affected through the [distributional parameters] so the the idea is the find out which [parameter] is effected and how by the [explanatory variables]. Note that the "which" part has to do with [variable importance] while the how part on whether the  effect is linear or nonlinear and whether there are [interactions] between the [explanatory variables]


#### model interpretation

The [model interpretation] is the state, of a [statistical modelling] process in which after an [adequate model] is found, we are trying to answer the [questions] of the study using the [fitted model].

#### model prediction

The [model prediction] is the state, of a [statistical modelling] process in which after an [adequate model] is found, the model is checked on [out of bag], new data. Thet is, [data] which have been not used for the [training] of the model.

#### multicollinearity

::: callout-note
We need a definition
:::

#### multivariate distribution

A [distribution] function [pdf] for more that one \[random\] variable.

################################################################################ 

::: {.page-break}
:::

## N

#### $n$ {#n-1}

$n$ is number of observations in a [tabular data] set

#### natural variability

See [natural variation].

#### natural variation

The [natural variation] refers to the variability in the [data]. The idea behind is that even if we were able to collect data more that ones from the same [population], under similar conditions, the data will be different reflecting the [natural variation] of the data. This makes necessary to use a [stochastic model]. In [regression analysis] the [natural variation] is reflected in the variation of the [response] variable. Even if we be able to collect data at the same values of the explanatory variables the response will be different.

#### nested models

Let us have two model $m_1$ and $m_2$. We say $m_1$ is nested in model $m_2$ and denote it as $m_1 \in m_2$, if $m_1$ is a special case of $m_2$. The idea of [nested models] is easily defined in [mathematical model]s. For example let $m_1$ be a linear model with only one explanatory variable $x_1$, i.e, $\beta_0+\beta_1 x_1$ and $m_2$ a linear model with two explanatory variable $x_1$ and $x_2$, i.e. $\beta_0+\beta_1 x_1+\beta_2 x_2$. We say that $m_1$ is nested to $m_2$ because $m_1$ can be obtained by $m_2$ by setting the parameters $\beta_2=0$.

#### normalised randomosed quantile ressiduals

::: callout-note
We need a definition
:::

#### neural network

Neural networks were not invented by a single person; they developed over time through contributions from several key researchers. The origins are usually traced to the following milestones:

-   Warren McCulloch (neuroscientist) and Walter Pitts (logician) proposed the first mathematical model of a neuron. Paper: “A Logical Calculus of the Ideas Immanent in Nervous Activity”Introduced binary neurons with thresholds. Laid the theoretical foundation of neural networks

-   Frank Rosenblatt (1957–1958 Frank Rosenblatt invented the Perceptron, the first learning neural network. Could learn weights from data , Implemented both in theory and hardware Major step toward modern machine learning Commonly credited with inventing the first trainable neural network

-   Minsky & Papert (1969). Marvin Minsky and Seymour Papert showed theoretical limitations of single-layer perceptrons. Temporarily slowed neural network research Their work motivated multi-layer networks

-   Backpropagation (1980s). Modern neural networks became practical after the rediscovery of backpropagation: Paul Werbos (1974): first formulation, Rumelhart, Hinton & Williams (1986): popularised it. Backpropagation made training multi-layer networks feasible.

-   1943 Artificial neuron model McCulloch & Pitts

-   1958 Learning neural network Rosenblatt 974–86

-   Backpropagation

-   Werbos; Rumelhart, Hinton, Williams 2010s ?? Deep learning boom Many contributors



#### normal distribution

::: callout-note
We need a definition probably from book 2
:::

#### normalized quantile residuals

The [normalized quantile residuals] or [z-scores] are the residuals of a [distributional regression] [model]. Residuals in a DR model are defined differently from the classical regression models. In classical models the residuals are defined as the difference between the response and its estimated mean value $(y_i-E(y_i)$. [Residuals] in a [distributional regression] model are the \[normalised quantile residuals\], (NQR) @DunnSmyth96 or [z-scores]. Two transformations are needed to get the z-scores from a fitted distributional model. Let $y_i$ and $F(y_i, \hat{\boldsymbol {\theta}}_i)$ be the $ith$ observation of the response and its fitted cumulative distribution function [cdf], respectively. Then first transformation is to get the probability integral transformed (**PIT**) residuals which are defined as, $$\hat{u}_i = F(y_i, \hat{\boldsymbol {\theta}}_i).$$ {#eq-PITresid} If the distribution of $y_i$ is specified "correctly" then the PIT residuals are expected to behave as identical and independently distributed (i.i.d) random variable from a uniform distribution i.e $u_i \sim U(0,1)$. The problem is, that is rather hard to check deviation from the uniform distribution, so we take the PIT residuals and transform them to z-scores using $$\hat{z}_i = \Phi^{-1}(\hat{u}_i).$$ If the assumed distribution of the response is approximate "correct" the z-scores are i.i.d. standardised normally distributed random variables i.e. $z_i \sim N(0,1).$

The two transformations needed to create the z-score residuals are shown in @fig-resid_types. In @fig-resid_types (a) the response is transform to a PIT using the fitted cdf function $F(y_i, \hat{\boldsymbol {\theta}}_i)$ while In @fig-resid_types (b) the PIT are transformed to z-score using the inverse cdf of the normal distribution $\Phi^{-1}(0,1)$ (otherwise known as the q-function of the normal distribution). While the above residuals works perfectly for [continuous distribution]s are not ideal for discrete counts especially if the range of the response is limited to small range i.e. $0,1,\ldots,10$. A randomisation of the PIT residuals between the values $y_i$ and $y_i+1$ usually solves the problem see for example Chapter 10 of @Stasinopoulosetal2017.

```{r}
#| echo: false 
#| warning: false
#| message: false
#| fig-cap: "The two transformation needed to get the residuals"
#| fig-subcap: 
#|     - "The PIT transormation (from cdf to uniform)"
#|     - "The z-scores transormation (from iniform to normal)"
#| layout-ncol: 2
#| label: fig-resid_types 
library(gamlss.ggplots)
library(ggplot2)
library(gamlss)
library(gamlss2)
op <- par(mfrow=c(1,2), mar=par("mar")+c(0,1,0,0) )
da <- dbbmi[db$age>10&db$age<20,]
m6 <- gamlss(bmi~age, data=da, trace=FALSE, family=BCTo)
y100 <- da[100,]$bmi
u100 <- pBCTo(y100, mu=fitted(m6, "mu")[100], sigma=fitted(m6, "sigma")[100], nu=fitted(m6, "nu")[100], tau=fitted(m6, "tau")[100])  
fitted_cdf_data(m6, 100, from=10, to=30, title="")+
  ylab("PIT")+
 ggplot2::geom_vline(xintercept = y100, colour="pink")+  
 ggplot2::geom_hline(yintercept = u100, colour="pink")+
  geom_text(x=y100+0.15, y=.01, label="Y")+
  geom_text(x=10-0.15, y=u100, label="U")+
  geom_segment(aes(x=y100, y=0, xend=y100, yend=u100), arrow = arrow(length=unit(0.4, 'cm')))+
  geom_segment(aes(x=y100, y=u100, xend=10, yend=u100), arrow = arrow(length=unit(0.4, 'cm')))+
   theme_bw(base_size = 20)
###################################
z100 <- qNO(u100)
p9 <- ggplot(data.frame(u = c(0, 1)), aes(x = u)) +
        stat_function(fun = qnorm, lwd=1.5)+
        ylab("z-score")+
   ggplot2::geom_vline(xintercept = u100, colour="pink")+
   ggplot2::geom_hline(yintercept = z100, colour="pink")+
   geom_text(x=u100+0.08, y=-2.3, label="U")+
   geom_text(x=-0.01, y=u100, label="Z")+
   geom_segment(aes(x=u100, y=-2.3, xend=u100, yend=z100), arrow = arrow(length=unit(0.4, 'cm')))+
  geom_segment(aes(x=u100, y=z100, xend=0, yend=z100), arrow = arrow(length=unit(0.4, 'cm')))+
   theme_bw(base_size = 20)
p9
par(op)
```

In conclusion, if the assumption of the distribution for the response is adequate for the given data then we expect $$\hat{z}_i=\Phi^{-1}\left(F_o(y_i,\hat{\boldsymbol {\theta}}_i)\right)$$ {#eq-z-scores} for $i=1,2,\ldots,n$ to behave like a i.i.d normally distributed variables, that is a [white noise].

#### null model

As null model we refer to a model with no \[terms\] in it. In R notation this is the model with a [model formula] equal to `~1`. For distributional regression a null model is model which has [model formula] `~1` for all the [distribution parameters] models.

################################################################################ 
::: {.page-break}
:::


## O

#### objective measure

An [objective measure], is an [empirical Risk] [measure] which is used to evalute a [model] either on the [training] [data], (a [training measure]), or on the [test] [data], (a [test measure]). The training [measure] is use as a [measure] of [goodness of fit] while the [test measure] to compare [model]s and for prediction. For example, the least squares, method uses a [MSE] evaluated in the [training] [data] to [fit] a linear model, while for GLM and GAMLSS the deviance, \[-2 log likelihood\], in the [training data] is used. The GAIC, a penalised version of the deviance, evaluated an the [training] [data] set is used to compared models. Alternative the [test] [deviance] a deviance evaluated at the [test] [data] can be used.

#### observations

We usually refer to the rows of a [tabular data] as the [observations]. Note that the number of observations in the [data] is denoted as [$n$](#n-1).

#### ordinary differential equations

::: callout
We need a definition
:::

#### Occam’s principle {#occams-principle}

The [Occam’s principle](#occams-principle) from the Latin "Entia non sunt multiplicanda praeter necessitatem" (“Entities should not be multiplied beyond necessity.”) it says that "among competing explanations, the one with the fewest assumptions should be preferred". The principle does not say the simplest explanation is always true but a simpler models is preferable if explain the data equally well and complexity should not be introduce unnecessary. In [statistical modelling] for [mathematical model] it means [model] with fewer parameters are preferable if they explain the model well or more generally if two models fit the data similarly, choose the one with fewer predictors. Note that if models fit the data similarly they belong the [Rashomon set] of relevant models.

#### over fitting

Over fitting happens when the [fit] is too close to the [data] and therefore do not generalised well when try to \[predict\], see also [over fit].

#### over fit

By [over fit] we mean situations where the model is too close to the actual [data] but not close to the [population]. An \[overfitted model\] is not good for predilection purpose, see also [over fitting].

#### out of bag

By [out of bag] [data] we refer to [data] that they have not be used to [fit] the [model]. That is, [test] or [validation data] sets.

#### outliers

::: callout-note
We need a definition
:::

################################################################################ 
::: {.page-break}
:::

## P

#### p-value

::: callout-note
We need a definition
:::

#### pacf

The term [pacf] stands for partial [autocorrelation] function. The [acf] and [pacf] are [diagnostic tool]s for detecting [autocorrelation] in a [vector], $\text{x}$.

```{r}
#| warning: false
# library(gamlss.ggplots)
# y_pacf(resid(m1))
```

#### pairwise relationship

By [pairwise relationship] we refer to the relationship between two [vector]'s in the [data]/[sample]. The investigation of [pairwise relationship]s between the explanatory variables could lead to the identification of possible problens in the [fit] of [interpretation] of a [model]. The identification of [pairwise relationship]s between the [response] variables could lead to better construction of a [multivariate distribution] via [vine copula].

#### parsimony

The principal of parsimony is what is also known as [Occam’s principle](#occams-principle) state that

#### partial effects

::: callout-note
We need a definition probably from book 3
:::

#### partial differential equation

A [partial differential equation] (PDE) is an equation that involves partial derivatives of a function and	a function of two or more independent variables. If a function depends on more than one variable, for example $z = u(x, y)$ then its derivatives with respect to $x$ and $y$ are partial derivatives $\frac{\partial z}{\partial x}, \ \frac{\partial z}{\partial y}$. A PDE is an equation involving these derivatives. There are **first order**, $\frac{\partial z}{\partial x} + \frac{\partial z}{\partial y} = 0$, and **second order**, $\frac{\partial^2 z}{\partial x^2} = 0$, PDE's. First-order PDE constrains the tangent plane of the surface at every point. Second order PDE, measure **curvature** of the surface.

Some important PDEs
are;
 
 - the _heat equation_ (diffusion): $\frac{\partial z}{\partial y} = k \frac{\partial^2 u}{\partial x^2}$ whete the first derivative is proportional to the second, 

 -  the _wave equation_: $\frac{\partial^2 z}{\partial t^2} = c^2 \frac{\partial^2 z}{\partial x^2}$ and 

- the _Laplace equation_:
$\frac{\partial^2 z}{\partial x^2} +
\frac{\partial^2 z}{\partial y^2} = 0$

For equations of the form $ A z_{xx} + B z_{xy} + C z_{yy} = 0$ The PDE are classified using the $B^2 - 4AC$ as

- _elliptic_  when  $B^2 - 4AC < 0$ (Laplace equation)

-	_parabolic_ if  $B^2 - 4AC = 0$ (heat equation) or 

- _hyperbolic_ if  $B^2 - 4AC > 0$ (wave equation)

DEs are important because are used to describe, heat flow,	fluid dynamics, electromagnetism, quantum mechanics, population dynamics, 	finance (e.g., Black–Scholes equation) etc. Goemetricaly the function $z = z(x,y)$ defines a surface in 3D. The first derivatives $\frac{\partial z}{\partial x}, \frac{\partial z}{\partial y}$. are slopes of the surface in the $x$-direction and $y$-direction and together they form the _gradient vector_ $\nabla z = \left(\frac{\partial z}{\partial x}, \frac{\partial z}{\partial y}\right)$. Geometrically the gradient points in the direction of steepest ascent and its length is the steepest slope.

A PDE is a rule that restricts how the tangent plane and curvature of a surface behave at every point. It doesn’t just describe the actual function but describes how the shape of the surface is allowed to bend and tilt everywhere.


In differential geometry we study **manifolds**. If the function $z = u(x,y)$ exist 
then its graph  $(x,y,z(x,y))$ is a 2-dimensional surface embedded in $\mathbb{R}^3$. Differential geometry studies: tangent planes, curvature, geodesics and intrinsic structure. A PDEs often describe geometric properties of these surfaces.
At each point of a surface we have a tangent plane. The gradient
$\nabla z = (z_x, z_y)$ determines that plane. A first-order PDE $F(x,y,u,u_x,u_y)=0$
geometrically: restricts which tangent planes are allowed. o a first-order PDE defines a constraint on the tangent bundle of the surface. This is why characteristics appear — they are curves along which the tangent constraint propagates. Second derivatives measure curvature. In differential geometry we define, Gaussian curvature, Mean curvature and Second fundamental form.  For a surface $z(x,y)$, curvature depends on $u_{xx}, u_{xy}, u_{yy}$ so the  second-order PDEs often prescribe curvature.



#### parameters

We refer to [parameters] as an generic term for all the unknown quantities within a [model]. The model [fit] estimates those [parameters]. The [parameters] of a \[distribution regression\] framework are of three types: the [distribution parameters] which are modelled as functions of the [explanatory variables] i.e. $\boldsymbol{\theta}_k = g(\textbf{X}_k)$, the [coefficients] describing the relationship between the \[distribution parameter\]s and the [explanatory variables]. and the [hyper parameter]s which are parameters which tune the mdel to the direction of the [data].

#### Poisson distribution

::: callout-note
We need a definition probably from book 2
:::

#### population

The population is often the object we would like to study. The population is related to the [purpose] of the study. The idea behind is that we collect a [sample] ([data]) from the [population] of interest and use a [model] to drew [statistical inference] about the [population]. The process of [statistical inference] it is shown in @fig-population. We need information about the [population] but we only have a [sample]/[data] form the population which is assumed to be obtained after a [data generating mechanism]. We make [assumptions] to create [model] which is then use to say something about the [population]. Going from the model to the population is called [statistical inference]. Note that any [statistical inference] is heavily depends on the [model] which itself depends on the [assumptions] and the [data generating mechanism]. If anything go wrong with the [assumptions] [statistical inference] can be wrong.

```{mermaid}
%%| fig-width: 2
%%| fig-cap: "Statistical inference: how to go from the sample to the population."
%%| label: fig-population
flowchart TB
  P[population] 
  D(data generation mechanism)  
  S[sample-data] 
  M[model] 
  I(statistical inference)
  A(assumptions)
  P --> D
  D --> S
  S --> M
  M --> I
  I --> P
  A --> M
  D --> A
```

#### principle component regression

::: callout-note
We need a definition probably from the paper
:::

#### properties of the distribution

Please see [characteristics of the distribution]

#### properties of the distribution parameters

The [distribution parameters] have different properties by how they are defined within a [distribution]. Any [distribution] can be re-parametrised differently as far as the re-parametrisation end up with the some number of parameters as the original distribution. For [distributional regression] the specific parametrization do matter in order to help the [interpretation] of the [model]. Some parametrisations are more useful in practice that others. For example in a [distributional regression] it worth to have a parameter dealing with, where the centre of the [distribution] is, and whether this centre changes with [explanatory variables]. Those parameters are called [location parameter]s. Other parameters could describe how far from the centre each observations could fall. Those are called the [scale parameter]s. To describe asymmetry in the [distribution] we have the [skewness parameter]s. To distinguish [distribution]s with fat [tail]s we have the [kurtosis parameter]s. Notice that any [distribution] could have more that one parametrisation and that the specific parametrization could affect different [characteristics of the distribution].

#### power transformation

By [power transformation] in [distributional regression] framwork we mean the [transformation] of one of the $\textbf{x}$ the \[explanatory vatiables\] to a more suitable form to a [feature] to make it suitable for [regression analysis]. The [power transformation] is defined as $x_p=\textbf{x}^p$ so the variable $\textbf{x}_p$ is entering the formula rather than $\textbf{x}$. The parameters $p$ takes values typically in the [range] $0 \le p \le 1.5$. The transformations tries to make the values of the $\textbf{x}$ more symmetric and more even spaced.

#### purpose

The [purpose] of the study is the [hypothesis] the study is working on which in turn depends on the [questions] need to be answered.

#### pdf

A [pdf] is the [probability distribution function] for a \[random\] variable. The definition of a \[random\] variable is that it is associated with a [distribution]. Let $Y$ be a random variable associated with [distribution] $f(Y)$, we denote this as $Y \sim f(Y)$. The only property that the function $f(Y)$ must have is that it should add up to one.

#### penalised least squares

::: callout-note
We need a definition
:::

#### PIT residuals

The [PIT residuals] stands for the probability integral transformed residuals. Within a [distributional regression] framework The PIT are defined as, $$\hat{u}_i = F(y_i| \hat{\boldsymbol {\theta}}_i).$$ for $i=1\ldots,n,$ where $F(.,| \hat{\boldsymbol {\theta}}_i)$ is the assumed [cdf] of the fitted [model]. If the [distribution] of $y_i$ is \[adequate\] for the [data] then the [PIT residuals] are expected to behave as identical and independently distributed (i.i.d) random variable from a [uniform distribution] i.e $u_i \sim U(0,1)$. While the above definition of [PIT residuals] works perfectly for [continuous distribution]s the PIT resuduals are not ideal for [discrete distribution]s especially if the [range] of the response is limited e.g. $0,1,\ldots,10$. The problem appears for a [mixed distribution] or a [censored response] variable. In \[mixed distributions\] there is a small amount of discrete values which with disturb the look of the residuals. In a [censored response] we do not know the exact value of the [response] to calculate the correct PIP. A randomisation of the [PIT residuals] between the values $y_i$ and $y_i+1$ in discrete cases usually solves the problem see for example Chapter 10 of @Stasinopoulosetal2017. The problem is that in ths case we have dumplcate resudial values to consider.

Not that the probability integral transformed plays an important role in [copula] theory since a [copula], $C(.)$, is a multivariate [distribution] define on a $(0,1)$ [range] after a transformation of marginal \[random\] variables, e.g. let $f_1(Y)$ and $f_2(Y)$ be two marginal [pdf]s them the variable $u_1= F_1(Y)$ and $u_2= F_2(Y)$ are defined the two dimensional [copula] $C(u_1, u_2)$.

#### prediction

By [prediction], in a standard [regression analysis], we mean using the [model] [fit] to predict the behaviour of the [response]. Note, that in a [distributional regression] [model] there are two uncertainties associated with predicting of any future value of $Y$: i) uncertainty about the assumed [distribution] of $Y$ ans; ii) uncertainty about the [model fitting].

#### prediction interval

A [prediction interval] is a [confidence interval] intended to demonstrate the uncertainty about future values of a quantity of interest.

#### predictor

The word [predictor] has been widely used in statistical literature and therefore it has different meanings depending on the context. In general the word [predictor] means a quantity that is used to forecast or estimate an outcome, a [predictor] helps to predict something. It could a variable, a factor, or any piece of information that is used to predict a future or unknown variable.

In [regression analysis] a [predictor] it could mean one the [explanatory variables] used in the [model] to explain or predict the [response] variable. In this case its is synonymous with [explanatory variables], [independent variables], \[covariate\], or [feature] and often is denoted as $X$.

In [GLM]'s a **linear** [predictor] is $\boldsymbol{\eta}$, with fitted values defined as ${\hat{\boldsymbol{\eta}}}=\textbf{X} \hat{\boldsymbol{\beta}}$. In [GAM] and in [GAMLSS] $\boldsymbol{\eta}$ can not be called "linear" since some of the explanatory variables could end up as non-linear functions. We use instead the word [predictor]. In this case [predictor] mean the [vector] ${\boldsymbol{\eta}}_{\theta}$ used for the [link function] of the [model]. <!-- In [distributional regression] a [predictor] helps to model one of the [distribution parameters] i.e. $\boldsymbol{\theta}_i$. It help the [statistical modelling] process by ensuring that the [distribution parameter] $\boldsymbol{\theta}_i$ is always in the correct range. Consider the following example, let us assume that $0 < \boldsymbol{\theta}_i < \infty$ that is, $\boldsymbol{\theta}_i$ is always positive. If we modelled $\boldsymbol{\theta}_i$ as a function of explanatory variables i.e. $\boldsymbol{\theta}_i= c+s(x_1)+ s(x_2)$ occationally maybe $\boldsymbol{\theta}_i$ could go to negative values. But if we model the log of $\boldsymbol{\theta}_i$ using the [link function] $\eta_{\boldsymbol{\theta}_i}=\log(\boldsymbol{\theta}_i)=c+s(x_1)+ s(x_2)$ the parameter $\boldsymbol{\theta}_i= \exp(\eta_{\boldsymbol{\theta}_i})$ is always positive. --> A [predictor] is a one to one function of the [distribution parameters] e.g. $\boldsymbol{\eta}=g_{\theta}(\boldsymbol{\theta})$ where $g_{\theta}()$ is the [link function] which when modelling the parameter as a function of [explanatory variables] insures that the [distribution parameter] will be in the right [range].

#### pre-data analysis

We call a preliminary data analysis or [pre-data analysis] the stage od the analysis which inspect the data, before, and to help modelling. There three main reasons to do this analysis.

i)  to know your data better by looking at its **structure**; e.g. the size, whether [continuous variable]s or [factor]s and by taking nto the account \[missing observations\] in the [data];

ii) to **identify** [outliers], [transformation]s and associations between [term]s.

iii) possible [data partition]s.

@fig-pre-data shows how the [pre-data analysis] could help with modelling.

```{mermaid}
%%| fig-width: 2
%%| label: fig-pre-data
%%| fig-cap: "Pre-analysis of the data involves knowing more about the structure, identify peculiarities and portioning of the data."    
flowchart TB
  D[Data] --> P(preliminary data <br/>  analysis) 
  P --> S(structure)
  P --> I(identify)  
  P --> A(partition)
  S --> M[model]
  I --> M
  A --> M
```

#### prior weights

We define as [prior weights] the predefined weights assigned to observations in a [data] set before a [model] [fit]. The [prior weights] reflect the perceive relative importance of observations in the analysis.

Most of the fitting [model] functions in `R` have the option `weights` for defining [prior weights], e.g. `lm(y~x,weights=wt)`.

#### probability

The word [probability] is defined as a numerical measure, between 0 and 1, which shows how likely an event is to occur.

#### probability distribution function

A [probability distribution function] is the [distribution] function associated with a \[random\] variable, see also [pdf].

################################################################################ 
::: {.page-break}
:::


## Q


#### questions

The [questions] are the [purpose] of the study and what the researcher is interested to investigate by collecting the [data]. One should ways ask the question on whether the [data] could answer the [questions].



#### QQ-plot

A [QQ-plot], (a [quantile]-[quantile] plot), is a [graphic] [diagnostic tool] for comparing the distribution of a [vector] in the [data] set to a theoretical distribution by plotting their corresponding quantiles against each other.

Within a [distributional regression] a [QQ-plot] is used for checking whether the [residuals]/[z-scores] are normally distributed as it would be expected is the assumed distribution for the [response] is an [adequate distribution].

#### quantile

::: callout-note
We need a definition probably from book 2
:::

#### quantile based measures

The [quantile based measures] in a [distribution] are defined as a [characteristics of the distribution] based on the [quantile]s rather [moment]s. For example, the quantile measure are based on the \[mediam\] the [IQR] e.t.c.

#### quantile function

The [quantile function]if is the inverse of the [cdf], e.g. $F^{-1}(p)$. It maps probabilities, range $[0.1]$, of a \[random\] variable $Y$ to the actual values of $Y$. The [quantile function] provides an easy way to obtain quantile values of any random variable. In `R` notation the [quantile function] starts with `q`, e.g. `qNO()` for the [quantile function] of a [normal distribution].

```{r}
#| warning: false
#| fig-cap: "The quantile function of a BCT distribution with mu=1, sigma=.1, nu=1, tau=5."
#| label: fig-Q-function
#| 
Qfun <- function(p) {qBCTo(p, mu=1, sigma=.1, 
                           nu=1, tau=5)}
p9 <- ggplot(data.frame(u = c(0, 1)), aes(x = u)) +
        stat_function(fun = Qfun, lwd=1.5)+
        ylab("Q-function")
p9
```

#### quantile residuals

The [quantile residuals] also called [PIT residuals] see [residuals].

################################################################################ 
::: {.page-break}
:::


## R

#### $r$

$r$ is the number of [explanatory variables] or [input variables] in the data ƒ \#### random

The word \[random\] is used as equivalent to [stochastic]. A \[random\] [model] means that there are some [probability] statements in the [assumptions] of the [model].

#### random variable

A [random variable], $Y$, is a variable which has a [probability] [distribution]. We denote this as $Y \sim f( Y| \boldsymbol{\theta})$ where the symbol $\sim$ reads as "is distributed" and where $f()$ denote a [probability] [distribution] function [pdf] and the $| \boldsymbol{\theta}$ notation emphasise that useful theoretical distributions are depending on an unknown [vector] of [distribution parameters] $\boldsymbol{\theta}$. The more the parameters in $\boldsymbol{\theta}$ the more flexible the [distribution] is. Another important feature of a random variable is the specification of its [range] $\mathbb{R}(Y)$. The [range] is very important when we assume a distribution for the [response] variables.

#### range

This this refer to the [range] of possible values that a [random variable] takes. We use the notation $\mathbb{R}(Y)$ to describe the [range] of a random variable $Y$. There are two types of ranges in the real line for [continuous variable]s and in the integer line for [discrete variable]s.

#### Rashomon

The term [Rashomon] originates from Akira Kurosawa’s 1950's film **Rashomon**, where a single incident, a murder and an assault, is recounted by four witnesses, the bandit, the samurai’s wife, the samurai via a medium, and a woodcutter, each giving a vastly different version of what occurred. The film ends without resolving which account, if any, is accurate.

![](rashomon.png){width="400"}

#### Rashomon effect

The idea that different models all of them [adequate model]s could possible provide different interpretations of the same data set.

#### Rashomon set

Is the set of [regression] [model]s with similar [objective measure]s of goodness fit therefore it is difficult to distinguish between them. [Rashomon set]s are real, practical statistician encounter them all the time. Note that [Rashomon set]s are comon to over-parametrized models

#### regression

A [regression] [model] is an [stochastic] [input-output model] where the [explanatory variables], $X$, affect the [response] $Y$.

#### regression analysis

A [regression analysis] is an statistical [input-output model] analysis, analysing [tabular data]. Typically regression analysis is refer to [linear model]s but here we use the term to describe any [input-output model] relationship.

#### regression tree

::: callout-note
We need a definition
:::

#### reference curves

::: callout-note
We need a definition probably from book 1
:::

#### residuals

The residuals is a [vector] of length $n$ with each element measuring the difference between observed and fitted values. For a [linear model] the residuals are defined as $y_i-\hat{y}_i$ for $i= 1,\ldots,n$. where $\hat{y}_i$ is the fitted values of observation $i$. The $n$-observations have $n$ residuals. Residuals can be defined in both the [training] or the [test] data sets. Residuals from the training data can be used to check \[underfitting\] while residuals from the test data can be use for checking \[overfitting\] the data.

Two transformations are needed to get the z-scores from a fitted distributional model. Let $y_i$ and $F_o(y_i, \hat{\boldsymbol {\theta}}_i)$ be the $ith$ observation of the response and its fitted \[cumulative distribution\] function (cdf), respectively. Then first transformation is to get the probability integral transformed (**PIT**) residuals which are defined as, $$\hat{u}_i = F(y_i, \hat{\boldsymbol {\theta}}_i).$$ If the [distribution] of $y_i$ is specified "correctly" then the PIT residuals are expected to behave as identical and independently distributed (i.i.d) random variable from a uniform [distribution] i.e $u_i \sim U(0,1)$. The problem is, that is rather hard to check deviation from the uniform distribution, so we take the PIT residuals and transform them to z-scores using $$\hat{z}_i = \Phi^{-1}(\hat{u}_i).$$ If the assumed [distribution] of the response is approximate "correct" the z-scores are i.i.d. standardised normally distributed random variables i.e. $z_i \sim N(0,1).$

The two transformations needed to create the z-score residuals are shown in @fig-resid_types. In @fig-resid_types (a) the response is transform to a PIT using the fitted cdf function $F(y_i, \hat{\boldsymbol {\theta}}_i)$ while In @fig-resid_types (b) the PIT are transformed to z-score using the inverse cdf of the normal [distribution] $\Phi^{-1}(0,1)$ (otherwise known as the q-function of the normal distribution). While the above residuals works perfectly for [continuous distribution]s are not ideal for discrete counts especially if the range of the response is limited to small range i.e. $0,1,\ldots,10$. A randomisation of the PIT residuals between the values $y_i$ and $y_i+1$ usually solves the problem see for example Chapter 10 of @Stasinopoulosetal2017.

#### response

The response variables is the output variable in a [input-output model].

#### RMSE

The term stands for square Root of Mean Square Error. Its defined as $\text{MSE} = \sqrt{\frac{1}{n}\sum_{i=1}^n (y_i - \hat{y}_i)^2}$ and its a [objective measure] of goodness of fit\] for [regression analysis] [model]s. It can be calculated in both [training] or [test] data sets for a [objective measure] of goodness of fit or measure of [prediction] power, respectively. RMSE is **NOT** appropriate for [distributional regression] models unless the [purpose] of the study is on the centre of he assumed distributions.

#### risk

A [risk] function measure the accuracy of a [model] in terms for a specific [objective measure] of goodness of fit. The [risk] function is a function of both the [data] and the [model fitting] process. For \[regression model\]s where only the mean of the response is modelled as a function of explanatory variables , for example, $Y=g(X)+\epsilon$, it measure how accurate the function $g()$ is. The mathematical definition of a [risk] function is given as the average of a [loss] function. Let us define the [loss] function as the discrepancy measure between the [data] and the [model], $\ell oss()$. The expected value of a loss function $\ell oss$() is defined as the [risk] function. $$\mathbb{Risk}(g) = \mathbb{E}_{X,Y} [ \ell oss(\hat{g}(X), Y) ]$$ where $\hat{g}()$ is an estimate of the model unknown function $g()$, $X$, $Y$ are the pairs, of an \[input output model\] variables. The [risk] measures the average discrepancy between the assumed [model] and the [data].\
The problem with the above definition of the [risk] function is that involve taking expectations with respect to the input and output variables. Even if conditioning on the $X$'s we have to take expectation with repsect to $Y$. We can avoid the problem all together if we replace the [risk] function with the [empirical risk] which gives equal probability to each row of the [data] matrix. For example the [empirical risk] is defined as $$\mathbb{ER}(g) = \frac{1}{n}\sum_{i=1}^n [ \ell oss(\hat{g}(x_i), y_i)$$ Note that if the [loss] function is defined as minus the log [likelihood] (or the [deviance]) minimising the [empirical risk] is equivalent to maximising the [likelihood] function with rescect to the parameters of the model. Note that $\frac{1}{n}$ is just a constant not involved in the minimazation.

################################################################################ 

::: {.page-break}
:::

## S

#### sample

In statistics a [sample] has the same meaning as [data]. It called a [sample] because it is assumed to come from a bigger data set the [population] of interest.

#### saturated model

A saturated model is a model which has as many unkown parameters as the number of observations $n$

#### SBC

The SBC is another name for [BIC]. It stand for the Schwarz Bayesian Criterion for comparing fitted models.

#### scale parameter

::: callout-note
We need a definition probably from book 2
:::

#### Sklar's theorem

The Sklar's theorem , (@sklar1959fonctions) states that every multivariate [cdf] $F(x_1,\dots, x_r)$ with marginals [cdf]s $F1(x1)$, $\ldots$, $F_r(x_r)$ can be written as $$F(x_1,\ldots,x_r) = C_r[F_1(x_1),\ldots,F_r(x_r)]$$ for some appropriate r-dimensional copula $C_r$.

#### selection of terms

A selection of terms in distributional regression is the process of identify which [term] affect which parameter.

#### skewness

Skewness is a statistical measure indicating whether a sample [vector] is symmetric or not. Skewness is also applied to random vectors and therefore to theoretical distributions.

#### skewness parameter

::: callout-note
We need a definition probably from book 2
:::

#### simulation model

A [simulation model] is a [model] in which is computer simulated several times usually in thousand, in order to determine the future behaviour of the [subjects] of interest according the the [variables] in the model.

#### statistic

The term [statistic] refers to a function of the [data]/[sample]. For example, the mean of the vector $\textbf{x}$ in the [data] defined as $\bar{x}= \frac{1}{n}\sum_{i=1}^{n} x_i$ is a [statistic], since it is a function of the [data]. A [statistic] captures properties of the [sample] the same way that [moment]s and \[centile based measures\] caption properties of a theoretical distribution. In the past, it was common practice, to equate [statistic]s with their equivalent [distribution] characteristic to draw inference from the [population]. The practice almost abandoned after the introduction of [MLE].

#### statistical inference

Is the process of drawing inference from the [sample] to the [population] see @fig-population for more explanation. The path from to the specific ([sample]) to the general ([population]) can only be achieved using [assumptions] and therefore is very treacherous and irrelevant if the assumptions are not correct.

#### statistical model

A [statistical model] is synonymous with a [stochastic model], that is, a [model] containing a mathematical component to describe relationships between the variables and a [probability] component to describe uncertainty.

#### statistical modelling

Statistical modelling is the art of creating a [statistical model] to represents the [data] adequately. @fig-mod_2 shows the [statistical model] as a filter which extract [information] from the [data]. This either because we would like to go back to the [population], a process known as [statistical inference] or because we would like to gain knowledge from the [information] in the data, a process known as [data analysis]. The [information] is needed to answer the [questions] posed by the researcher which are essential the [purpose] of the study.

```{mermaid}
%%| fig-width: 2
%%| label: fig-mod_2
%%| fig-cap: "Showing how a model is behaving as filter to extract information from the data"
flowchart LR
  D[data] --> M[statistical <br \> model] 
  M --> I(information)
```

<!-- The will refer to [questions] are the main [purpose] of the study.  -->

`Statistical modelling is a process`.

By considering the components of the proceed we are hoping to be able to identify the pitfalls. @fig-model shows how the [statistical modelling] process works: the [data], the [model] and the [questions] to be answered from the [data] are all inter-connected and to emphasize this all three components are shown in the same box. Typically the [data] are collected to answer the [questions] and the [model] is the filter to get the important information for the [data] to answer the [questions].

```{mermaid}
%%| fig-width: 2
%%| label: fig-model
%%| fig-cap: "The modelling process: the data, the model and the questions are inter-related. The model needs assumptions before the fit and an adequate fit help to answer the questions."
flowchart TB
  subgraph stats-modelling-process
   style stats-modelling-process fill:#e3f2fd,stroke:#1e88e5,stroke-width:2px
    direction TB
    D[data]
    M[model]
    Q[questions]
  end
 A(assumptions) 
 G(training <br \>  measure)
 F(model <br \>  selection)
 I(interpretation)
 
 A --> M
 M --> F
 F --> I
 I --> Q
 M --> G
 G --> F
```

This bring us to the fist question every statistical modelled should ask;

`Is the data or the model capable to answer the questions?`

If the answer is yes, [assumptions] are needed to build the [model]. The [assumptions] reflect the flexibility of the model. The [assumptions] can be;

-   **explicit** (mostly true for [mathematical model]s) or
-   **implicit** (mostly true for [algorithmic model]s).

<!-- Probably, at this stage, we would have to decide the type of model we would like to use; should be a [mathematical model] or an [algorithmic model]?. -->

Note that most [model]s analysing [data] use mathematics to model the relationships between variables. For example, in [distributional regression] each of the [parameters] of the [distribution] is a function of the [explanatory variables], e.g. $$\boldsymbol{\theta}_i= G(\textbf{x}_1, \textbf{x}_2, \ldots, \textbf{x}_r).$$ One of the tasks of a [model selection] is to estimate $G()$ accurately. Subsequently we will use the definition of a [mathematical model] as a model in which the interpretation of $G()$ is simple and the definition of an [algorithmic model] as one in which the  interpretation of $G()$ rather difficult so we treat it as a [black box]. Our definition is in line to @breiman2003statistical distinction between [data modelling] and [algorithmic modelling]. I our case  we did not like the [data modelling], because it is implies any [model] involving [data]. We use instead the distinction between [mathematical model]s and [algorithmic model]s (even though the latest have mathe mathematic in it).  If in addition a [model] contains a [stochastic] part, that is, it relies on [probability] statements, the we have a [statistical model] or [stochastic model].

Any [statistical model] needs an [objective measure], a function describing the **distance**, between the [data] and the [model]. We would like to divide the [objective measure] in two components accord to in which [data] are used to evaluate it;

-  a [training measure] is  a [goodness of fit] [measure] evaluated at the [training] [data], and used at the [model fitting] stage to [fit] the model;

-  a  [test measure] is a [goodness of fit] [measure] evaluated at the [test] [data], for [model comparison] and [prediction] performance.

Note that the same [objective measure] can be used for both the [training] and the [test] data, when [data partition] is involved. Both the [test] and [training] [measure]s should be relevant to the [questions] to be answered. For example, if the interested lies in the tail behaviour of the [response] we should never use an [test] or [training] [measure] concentrating at the centre of the distribution of the [response] likefor example, [MSE].

<!-- Usually fitting is done at the [training] data set, and called  the [training measure].  In our  opinion, the comparison should be  done  on the [test] [data] using a [test measure]. The two measure could be the same or different, but in both cases should be evaluated at partitioned data.  It is the researchers choice whether to use the same [measure] or not.  -->

`Do not use a test measure, concentrating in the center of the distribution i.e. MSE, if the questions are related to the behaviour of the tail of the distribution of the response`.

After a [model selection] procedure an [adequate model] is selected, and the [interpretation] of the model begins to help answering the [questions]. Using a [model selection] procedure to find an [adequate model] is the essence of any [statistical modelling] process. A [model selection] procedure tries to identify the model best suited for the [data]. For distributional regression it involves two distinct step.

- identify the [distribution] for the [response];

- identify **which** [explanatory variables] and  **how**  it affect the distribution of the [response]. 


The "which" part is associated with [variable importance] and the  "how" part is associated on whether the effect is linear of not and whether there are [interactions] in the model.  

<!-- so next we spend more time to examining how we can achieve that. Note that  in order to prove that we have an  [adequate model] we have to show that the is no proof for the opposite. -->

@fig-mod_5 shows what we called the **classical statistical modelling process** [something we believe was first mentioned by @BoxJenkins70 in their famous [time series](#time-series) book.] The process starts with the [data] and after going through a loop several times it ends with an [adequate model] for [interpretation]. The loop is around the [assumptions], the [model], the [fit], (using an appropriate [objective measure] of [goodness of fit]), the [diagnostics] and back into the [assumptions]. That is, [assumptions] are made, the [model] is [fit]ted and if the [diagnostics] and the [objective measure] indicate an inadequate [fit] different [assumptions] are made and the process is continuing until an [adequate model] is reach.

```{mermaid}
%%| fig-width: 2
%%| label: fig-mod_5
%%| fig-cap: "The classical statistical modelling process introducing a loop between assumptions, model, fit and diagnostics"
flowchart TB
  D( data  <br \> training ) --> A(assumptions) 
   A --> M(model)
   M --> Y[adequate <br \>  model]
   M --> W(fit)
   G(training <br \>  measure) <--> W
   W --> V(training <br \> diagnostics)
   V --> A
   Y --> I(interpretation)
```

By [adequate fit] we mean a model close to the [data] but also able to answer the [questions] in the [interpretation] stage. How close to the data a model is, can be checked by the [training measure] and by different [diagnostics]. Note that any [objective measure] is a relative [measure] in the sense that it help with [model comparison] but is not good for demonstrating an [adequate fit] on its own. This task mainly lies with [diagnostics], or more specificity [diagnostics] based on the [residuals]. Diagnostics are plots or function involving both the fitted [model] and the [data] and therefore we divide them into [training] and [test] [diagnostics]. The main reason why most [diagnostics] involve the [residuals] is because for all [statistical model]s, if the the [assumptions] of the model are correct (or nearly correct), we expect the [residuals] to behave as a [white noise]. Diagnostic plots demonstrating the existence of a [white noise] in the [residuals] are a good sign that an [adequate fit] has been reached. The fact that we reach an [adequate fit] do not mean that we have avoid [over fit].

Note that for a given [data] set they can be more than one [adequate model]s. The set of all [adequate model]s is refer to as the [Rashomon set]. This is, the [Rashomon set] contains a [stack] of different fitted [model]s, all of them adequate, believable with no good argument against them. The process of reaching the [Rashomon set] is shown in @fig-rashomon.

```{mermaid}
%%| fig-width: 2
%%| label: fig-rashomon
%%| fig-cap: "Showing the process of creating a Rashomon set of models"
flowchart TB
    direction TB
    R[Rashomon <br \>  set or <br \> stack]
    D[diagnostics]
    G(objective <br \> measure)
    M[models]
    A[assumptions] 
  A --> M
  M --> D
  M --> G
  G  --> R
  D --> R
```

In conclusion, an [adequate fit] can be verified using training residual [diagnostics] and because a [training measure] shows that a [model] is better that other [candidate model]s. To verify that the [model] is not [over fitting] the [residuals] [diagnostics] and the [objective measure] should be evaluated at the [test data] set.

There are two addition components to statistical modelling process that make the process more flexible.

-   the [data partition] and

-   [model average]

The [data partition] into say [training] and [test] data helps the detection of [over fitting] and improve the [prediction] power of a model. The [model average] help with the problem of having a [stack] of [model]s. Instead of having to chose a single model out of the stack of models we can average them. @fig-modelling_modern show this new approach of statistical modelling. The [data partition] allows the [objective measure] and the [diagnostics] to be evaluated at the [test] [data]. The [model average] allows instead of a single fitted model multiple models to be [fit]ted and subsequently to be aggregated. Note that aggregate models are more difficult to interpret.

```{mermaid}
%%| fig-width: 2
%%| label: fig-modelling_modern
%%| fig-cap: "The modern modelling process uses data partition and  model aggregation."
flowchart TB
   D[training <br/>  data] --> A(assumptions) 
   A --> M(model)
   M --> Y[stack of <br \>  models]
   M --> W(fit)
   G[training <br \> measure ] <--> W
   W --> V(diagnostics)
   V --> A 
   Y --> E(select using <br /> test measure <br /> or aggregate) 
   E --> Q(interpretation) 


   style Y fill:#f9f,stroke:#333,stroke-width:2px
   style E fill:#f9f,stroke:#333,stroke-width:2px
   style D fill:#f9f,stroke:#333,stroke-width:2px
```

@fig-modelling_modern shows the more modern approach of statistical modelling procees. @fig-modelling_modern is similar to @fig-mod_5 with he addition of [data partition] and [model aggregation]. The additional new components are highlighted with different colour. Note that the [data] the [model] and the [questions] answered by the [interpretation] are interconnected. The [data partition] come from the data to help [inference].

<!-- ```{mermaid} -->

<!-- %%| fig-height: 3 -->

<!-- %%| label: fig-modelling_modern -->

<!-- %%| fig-cap: "The modern modelling process uses more models and aggregates them" -->

<!-- flowchart TB -->

<!--   D(data <br/>  partition) A(assumptions)  -->

<!--   A -->

<!--   O(objective <br/> measure) --->

##### pitfalls

Because [statistical modelling] is a process there are a lot occasions where the process itself could go wrong. Those occasions mostly have to do with how the components of the process interact with each other.

-   [data]-[model]:

    -   the [model] is too simple to represent the [data], this sometime is called [under fitting] and it effect both [estimation] and [prediction].

    -   the [model] is too complicated to represent the [data] properly, this sometime is called [over fitting] and affect prediction

    -   the [data] do not incluse important [term]s. For a [regression analysis] [model] that will effect the distibution of the [response].

-   [data] - [questions]: the [data] do not answering the [questions]; wrong data choice.

-   [model] - [questions]: the [model] do not answering the [questions]; wrong model choice.

-   [data] - [assumptions]: The assumptions are related with the data only in the case that assumptions are made about the [data generating mechanism]. If the assumptions about the [data generating mechanism] are wrong the [interpretation] maybe wrong. Remember that the [data generating mechanism] are assumptions on how the [data] are generated.

-   [assumptions]-[model];

    -   if the [model] do not include appropriate non-linear [term]s;

    -   if the [model] do not include important [interactions] of [term]s.

    -   if a wrong [data generating mechanism] is assumed could effect the choice of the [objective measure]

    -   For regression type of models, if the response assumed distribution is not representative of the distribution of the [response] in the [data];

-   [questions] - [objective measure] The [objective measure] used for the [fit] and [model comparison] should be in line with the [questions]. For example if the researcher is interested in what happens on the tail of the distribution of the response the corresponding [objective measure] should be chosen appropriately.

As an example of too simple [model] consider the [linear model], LM, which dominated statistical analysis because of their simplicity and interpret-ability. However LM can not catch easily non-linear relationships neither [interactions] unless are explicitly stated and fitted. the [neural network] [model] though can but at the cost of interpret-ability because there [black box]s.

Another common mistake has to do the fact that the [objective measure] is not able to answer the questions. Consider [machine learning] [model]s at least as they are used in [regression analysis]. Implicitly [machine learning] are appropriate for symmetric [response] variables. For example, most [machine learning] [regression analysis] models have the form\
$$y_i= a+g(\textbf{x}_i)+\epsilon_i$$ for $n=1,2,\ldots,n$ where $y_i$ is the response, $\textbf{x}_i$ is the vector of [explanatory variables] and $\epsilon_i$ the error for observation $i$, respectively, and $g()$ is a generic function which should be estimated from the algorithm models. Those models are not suitable for hight skew [response] variables. The situation is getting worst when the [questions] to answer depends on the [tail]s of a the distribution of the response e.g. the extreme values. We advice people;

`never to use a symmetric distributions to model a skew response variable if the interest of the analysis is on the tails`

##### extra

Often we assume that there exist a [population] of interest and there is [data generating mechanism] which creates the observed [data] (called the [sample]) as shown in @fig-mod_1.

```{mermaid}
%%| fig-width: 2
%%| label: fig-mod_1
%%| fig-cap: "The relationship of the population and the data/sample."
flowchart LR
  P[population] --> G(data <br/>  generating <br/>   mechanism) 
  G --> D[data]
```

In order to create a [model] we need to make [assumptions]. The [assumptions] should reflect the believed [data generating mechanism], the [data] and the [purpose] of the study, as shown in @fig-mod_3. Note that the assumption also effect the measure of [goodness of fit] One should always ask the question on "whether the [data] or the [model] could answer the [questions]. The [assumptions] should account for the [natural variation] in the [data] but also able to capture the relationships between the variables in the [data].

```{mermaid}
%%| fig-width: 2
%%| label: fig-mod_3
%%| fig-cap: "A model need realistic assumptions to capture both the natural variable and ther interrealtioships in the model."
flowchart TB
  G(data <br/>  generating <br/>   mechanism)  --> D[data]
  D --> M[model] 
  A(assumptions) --> M
  G --> A
  M --> I(information)
  D --> A
  M --> Y[objective <br \> measure]
  I --> Q[questions]
  Y --> Q
```

The quality of the [information] to extracted in the [data] depends on the flexibility of the [model] and how realistic are the [assumptions]. Wrong [assumptions] could lead to wrong conclusions and therefore to wrong [interpretation]. This fact was recognise at an early stage of [statistical modelling] and lead to the introduction of [diagnostic tool]s for checking the appropriateness of the [assumptions]. A diagnostic is a [statistic] or a [graphic] which as a function of both the [data] and the [model] could check whether the assumptions of the [model] are adequate. A lot of the graphical [diagnostics] are based on the [residuals] of the [model] which if the [assumptions] are correct are expected to behave as [vector] of [white noise]. Typical examples are [QQ-plot]s and [worm plot]s.



#### statistical model

A [statistical model] is a [stochastic model]. that is a [mathematical model] containing probabilistic statements to account for the [natural variation] of the data.

#### stack

A [stack] of [model]s is set of different fitted models. we call a [stack] of [adequate model]s the \[Rashonon set\] of models.

#### stacking

The idea of [stacking] is to [fit] several [model]s to single [data] set but instead of performing a [model selection] to proceed by averaging the resulting models. The problem with [stacking] is that very rare the procedure leads to good [model interpretation].

#### scope

The [scope] of a [step wise selection] procedure specify the range of all possible [candidate model]s to be checked. There is an order in the scope in that [main effect]s go before [first order interaction]s and before the higher order interactions. The scope can be specified by declaring the [lower model] and the [upper model]. Note that the [lower model] sould be a sub set of the [upper model].

#### scope of step wise selection

see [scope].

#### score test

::: callout-note
We need a definition
:::

#### step wise

See [step wise selection]

#### step wise selection

A [step wise selection] procedure is a way of selecting [term]s in a [regression analysis]. The procedure to work needs a [scope] which specify the range of all possible [candidate model]s to be checked. Usually there is an order in the [scope], The [main effect]s go before [first order interaction]s and before the higher order interactions. The scope should contain a [lower model] and and [upper model]. The procedure also needs two competitive models; the [current model] and the [candidate model]. Those two models are compared using an appropriate measure of [goodness of fit] and the "best" model is them selected as the new [current model] this is shown in @fig-step_wise.

```{mermaid}
%%| fig-width: 2
%%| label: fig-step_wise
%%| fig-cap: "The step-wise approache for selecting a term"
flowchart TB
  S[starting model] --> C(current model)
    C ---> M(fit candidate model)
    C --> Y[final model]
    M --> G(compare using goodness of fit)
   G --> C
```

The [starting model] becomes the [current model] as soon the procedure is starting. The procedure can go **forwards** (that is, after setting the [starting model] to the [current model]) trying to fit only more complicated models in the scope see @fig-step_wise_forwards;

```{mermaid}
%%| fig-width: 2
%%| label: fig-step_wise_forwards
%%| fig-cap: "The forward selection of terms "
flowchart LR
  S[lower model] -.- C(current model)
  C ---> M(upper model)
```

The procedure can go **backwards**, that is, trying to fit only simpler models in the scope see @fig-step_wise_backwards;

```{mermaid}
%%| fig-width: 2
%%| label: fig-step_wise_backwards
%%| fig-cap: "The backwards selection of terms "
flowchart RL
  S[upper model] -.- C(current model)
  C --> M(lower model)
```

Or the procedure can got **both** ways, that is, choosing the best model either way from the [current model].

```{mermaid}
%%| fig-width: 2
%%| label: fig-step_wise_both
%%| fig-cap: "The selection of terms going  in both directions."
flowchart LR
  S[upper model] <--> C(current model)
  C <--> M(lower model)
```

#### starting model

A fitted [model] to start the [step wise] selection procedure for selecting terms in a model. The first step of the procedure is to make the [starting model] the [current model]. Often the [starting model] is the [null model].

#### standard errors

::: callout-note
We need a definition
:::

#### SE

[SE] is and abbreviation for [standard errors].

#### stochastic

A \[random\] variable is [stochastic] if it has a probability distribution [pdf] associated with it. The term [stochastic] is equivalent with the term \[random\]

#### stochastic model

A [stochastic model] is a mathematical or an algorithmic model which incorporates randomness, interms of probabilistic statments. The output of a [stochastic model]is not completely predictable. Not all models need a stochastic component. A [mathematical model] or an [algorithmic model] donot have to be a stochastic model. A stochastic model contains [probability] assumtpions about one or more of his components.

#### stochastic regression

A stochastic regression models contain [probability] assumptions on how the input-output model is generated. A typical assumption is the response is a function of the explanatory variables plus an [error], for example, $\textbf{y} = g(\textbf{x}) + \boldsymbol{\epsilon}$ where The minimal assumption for a regression model is about the behaviour of the \`response. Not all problems need a stochastic component. Stochastic models are often used because many natural, social, and physical systems have an inherent variability.

#### study

In a [data analysis], a [study] is an investigation in which we are trying to understand the behaviour of the [subjects] at different values of the [variables]. Studies have a [purpose] consisting of the [questions] an investigator would like to answer.

#### smooth function

A [smooth function] $s()$ is a term in a [model] design to model non-linear relationships. In a [regression] model those relationships are between the [explanatory variables] and the [response], in a \[distributional regression model\] is between the explanatory variables and a \[distribution parameter\]. To simplify matters, consider the simple [regression] situation when we have only one explanatory variable, $\textbf{x}$ and one response $\textbf{y}$. If we suspect that the relationship is not linear we couls try a \[smooth\] **non-parametric** [model] for the response: $\textbf{y}= s(\textbf{x})+\boldsymbol{\epsilon}$. The function $s()$ is a general notation for a smoother. that is, a smooth function determined by tha [data]. It turns out that the **non-parametric** part is rather misleading because most of the smooth techniques are following this simple linear model $\textbf{y} = \textbf{B}  \boldsymbol{\gamma} + \boldsymbol{\epsilon}$ where $\textbf{B}$ is a basis matrix constructed by the values of the explanatory vector $\textbf{x}$. The estimation of the linear parameter $\boldsymbol{\gamma}$ (the length of which could be as big as the length of the data) is done using a [penalised least squares] method with solution $\hat{\boldsymbol{\gamma}}=(\textbf{B}^{\top} \textbf{B}+\lambda \textbf{I} )^{-1} \textbf{B}\textbf{y}$. Note that if more that one smooth functions exist in model [formula] then the estimation of the smooth functions is achieved using a [backfitting] algorithm.

#### smooth model

A smooth model is a model containing smooth functions. For example the simpler smooth model is $\textbf{y}= s(\textbf{x})+\boldsymbol{\epsilon}$.

#### smooth term

::: callout-note
We need a definition probably from book 1
:::

#### smoother

A smoother is a \[smooth\] non-parametric function design to model non-linear relationships see [smooth function].

#### stack of modelsƒ

A \[stack of model\] is set of [fitted model]s usually waiting for evaluation for their suitability to answer the [questions] of the study.

#### subjects

A subject is the basic unit of interest in a [study].

#### sufficient statistic

A [sufficient statistic] was a fundamental concept in statiscal inference in that tells you when a [statistic] captures all the information in the [data] about the [parameters]. It was a usefull concepts before computers but its usefulness is diminishing over yeaar since in most real lile situations [sufficient statistic] are not provided. The [exponential family] of [distribution] is the only family allow \[sufficient statistics\]ans this only for the mean, $\mu$.

#### summary statistic

A [summary statistic] is another wold for [statistic]

#### supervised learning model

A [supervised learning model] is a regression model in which a [response] exist.

#### survival function

If $F(.)$ is the [cdf] of the random variable $Y$ its [survival function] is defined as $S(Y)=1-F(Y)$ see also [exceedance probability].

```{r}
library(gamlss.dist)
S <- function(q, ...) {1-pBCTo(q,...)}
curve(S, from=0.001, to=10)
```

Or using `ggplot2`;

```{r}
 library(ggplot2)
 ggplot(data.frame(x = c(0, 10)), aes(x)) +
   stat_function(fun = S) +
   labs(x = "x", y = "S(x)")
```

################################################################################ 

::: {.page-break}
:::

## T

#### target

The [target] variables is the [response] variable in a [regression analysis]

#### time series

A [time series] [data] set is a data set when observations were obtained over time and therefore that is a high probability that they are not independently distributed but there is autocorrelation between sequential observations. A [time series] analysis is a methodology to deal with a \[time seriess\] [data].

#### Tobit model

::: callout-note
We need a definition probably from book 2
:::

#### top down model

A [top down model] in data analysis is model in which the [variables] influence all the [subjects] of the model globally. That is, there exist an influence at a **macro** level and this influence is the same for all subject. A regression analysis model is a [top down model]. Note that different behaviour in a cluster of the subjects could be modelled if the cluster is part of the model. For example if there is a male, female difference in behaviour then the factor gender should be part of the [model].

#### training data

The training data are the data used in the [fit] stage of a modelling process. The contrast with the [test data] and the [validation data] sets.

#### training deviance

A [deviance] evaluated at the [training] [data] is called [test deviance]

#### test data

The test data are the data used to check the prediction power of the model.

#### test deviance

A [deviance] evaluated at the [test] [data] is called [test deviance]

#### t distribution

see Student-t

#### t copula

A [t copula] is based on the multivariate Student-t and allows symmetric log tails dependence and therefore is more robust than the \[normal copula\]

#### tabular data

Tabular data are spreadsheet type of data sets. Tabular data are rectangular in shape with variables vertically and observations horizontally. We refer to the number of observations as $n$ and the number of variables as $r$. Over recent years we have seen an increasing in the size of data sets for both $n$ and $r$. Traditionally classical regression models supported the cases where $n\gg r$, where $\gg$ refers to “$n$ is much greater than $r$”. More recent regression techniques i.e [LASSO] ans \[PCR\] support situation where $n  \simeq r$, or even $n<r$, Note that the notation $\simeq$ refers to “$n$ is nearly equal to $r$". A typical tabular data example is shown in @tbl-TheTableofData.

##### Tabular data example {.smaller}

| obs number | y      | x~1~    | x~2~    | x~3~    | ... | x~r-1~    | x~r~    |
|------------|--------|---------|---------|---------|-----|-----------|---------|
| 1          | y~1~   | x~11~   | x~12~   | x~13~   | ... | x~1r-1~   | x~1r~   |
| 2          | y~2~   | x~21~   | x~22~   | x~23~   | ... | x~2r-1~   | x~2r~   |
| 3          | y~3~   | x~31~   | x~32~   | x~33~   | ... | x~3r-1~   | x~3r~   |
| ...        | ...    | ...     | ...     | ...     | ... | ...       | ...     |
| n-1        | y~n-1~ | x~n-11~ | x~n-12~ | x~n-12~ | ... | x~n-1r-1~ | x~n-1r~ |
| n          | y~n~   | x~n1~   | x~n2~   | x~n3~   | ... | x~nr-1~   | x~nr~   |

: A tabular data example {#tbl-TheTableofData .striped .hover}

#### tail

The word [tail] in [distributional regression] framework is refer to the [tail]s of the [distribution] of the response. The [tail] of a [distribution] is very important if the [purpose] of the study is extreme values or exceedance probabilities.

#### term

A [term] is one of the [explanatory variables] in a [model], after possible a [transformation] to make it suitable for [distributional regression] analysis. For example a [factor] is a [term]. A first order interaction is a [term].

#### test

A [test] data set is the part of the [data] keep out of from fitting the [model] in order checking the predictive power of the model using a [objective measure] of goodness of fit.

#### test measure

#### training

A [training] data set is the [data] set in which the [model] is [fit]ted.

#### training measure

#### transformation

By [transformation] we mean usualy a [vector] transformation, that is, a transformation of one of the columns of the [data] in something that it is more suitable for [statistical modelling]. In a [distributional regression] framework we rarely transforming the [response] variable, since the variability of the response is part of its assumed distribution. For example if we beleive that the response is highly \[skew\] to the left we caassume the log-[distribution] for $Y$ i.e `LOGNO` or `logTF`. Transformations in the $X$'s sometime do help the modelling process. Typically is if would suspect non-linearity in the relationship and we would like ot use a [smoother] to model it ideally the $X$s should be equal spaced with no outliers. A [power transformation] could help this. In [centile estimation] when we are dealing with a single $X$ variable (often `age`) a [transformation] of the $X$ maybe is necessary to achieve a good [model]. \[reference here $\ldots$ Rigby et al. 2026\]. Note that the timing for creating a new [feature] by transforming $X$ could be achieved before or during the [fit]ting a [model]. For the formal case see the function `trans()` in the package `gamlss.prepdata` for the later case see Fasiolo at al. $\ldots$.

################################################################################ 

::: {.page-break}
:::

## U

#### under fit

A [model] under fits the [data] if it is not close enough to the data. The closeness is evaluated using a [goodness of fit] measure like [GAIC]. The model under fits happens if is not flexible enough and therefore misses important information in the [data]. See also [under fitting]

#### uniform distribution

A [uniform distribution] is a probability distribution, pdf\], in which all values in a given range are equally likely. For continuous variable the most common case when the \[random\] variable $X$ is define in the range $(0,1)$ but it can be defined in any [range] $(\alpha,\beta)$. Often is denoted as $\text{U}(\alpha,\beta)$ and its probability density function is $$
\begin{split}
f(x) & = \dfrac{1}{b-a}, \qquad  a \le x \le b \\
     & = 0, \quad  \quad  \quad \quad \text{otherwise}
\end{split}
$$ It has mean $\frac{1}{2}$ and variance $\frac{1}{12}$. A uniform [discrete distribution] is a probability distribution, [pdf], in which each value in a finite set $x_1, x_2, \ldots, x_n$, has the same probability: $$
P(X = x_i) = \frac{1}{n}, \qquad i = 1,\ldots,n.
$$ Its mean is $(x_1+\cdots+x_n)/n$, and its variance depends on the spacing of the values. A typical example of a \[uniform\] [discrete distribution] is the distribution of a fair six sided die; $$
P(X = k) = \frac{1}{6}, \quad k = 1,2,3,4,5,6.
$$ Note that the [uniform distribution] is the distribution with the highest [entropy]. That is, a uniform distributed variable contains no [information].

#### univariate distribution

A [univariate distribution] involves only one \[random\] variable. Originally GAMLSS was developed for one [response] variable therefore its distribution was a [univariate distribution].

#### `update()`

The R function `update()` takes a fitted model and updates part of it. We found the function helpful in testing whether a model [fit]ted functions are sensitive when evaluated at the [test] [data]. For example

```{r}

```






#### under fitting

Under fitting occurs when the [fit] of a [model] is very poor according to a [goodness of fit] measure or [diagnostics] and therefore do does not represent the [data] properly, see also [under fit].

#### unsupervised learning

An [unsupervised learning] [model] also called a [classification model] is a model which has [explanatory variables] but not [response]. The model tries to guess what class the response belong to given the [explanatory variables].

#### upper model

The [upper model] is the most complex model in the range of all possible models to be selected in a [step wise] procedure.

################################################################################ 

::: {.page-break}
:::

## V

#### validation data

The [validation data] set is used for tuning a model. That is useful in estimating the [hyper parameter]s of a model. The [validation data] set is an [out of bag] data set.

#### variables

Variables are attributes of the [subjects] of the study. I data analysis [variables] are [vector]s in a [tabular data] matrix. Thos vectors can take a wide variety of values [continuous variable] vectors a or can take few values [categorical variable] often called [factor]s in statistics.

#### variable importance

A [variable importance] shows the important of a [term] in the [model]. In regression analysis is translate into how much a specific term contributes in explaining the [response]. In [distributional regression] a [term] affects both the model of a specific [parameters] of the [distribution] but also has an effect in reducing the [objective measure] of [goodness of fit]. For example, one should be able to ask both question; how important say **age** is for the $\sigma$ parameters, the variation the response $Y$; but also how important the term is in reducing the [objective measure] of [goodness of fit]. This is usually done in comparison with other terms in the model. For a [mathematical model] with linear parametric [term]s the size of the estimated coefficients for provide an indication of how important a variable. For smooth non-linear terms for local influence we may need the the fist derivative of the smooth function ar specified More generally is more difficult. An [agnostic method] in the literature (I think by Breimer) finds the prediction power of sa terms by scramble it and compared its the predictions with model containing the unscramble. The method produces indexes of importance for both models for parameter but also [objective measure] of [goodness of fit].

#### vector

In [statistical modelling] we refer to a [vector] as one of the columns in a [tabular data] set. In [regression analysis] both the [response] variable(s) and the [explanatory variables] are the [vector]s of interest for often we would like to explore their [pairwise relationship]s.

#### vine copula

The basic idea of a [vine copula] is, for a given [data] set, to build a multivariate [distribution] for the [response]s based their [pairwise relationship]s..

################################################################################ 

::: {.page-break}
:::


## W

#### white noise

The term [white noise] is used to describe a pure \[random\] process in the sense that knowing the past values will tell tell you nothing about the future values. More precise is refers to a sequence $\{\varepsilon_t\}$ of a \[random\] variable with $\mathbb{E}[\varepsilon_t] = 0$ $\operatorname{Var}(\varepsilon_t) = \sigma^2 < \infty$ and $\operatorname{Cov}(\varepsilon_t, \varepsilon_{t-k}) = 0$ for all $k \neq 0$. If in addition we assumed that $\varepsilon_t \sim \mathcal{N}(0,\sigma^2)$ then we have a [Gaussian white noise]. Note that [independence] implies [white noise] but the oposite is not correct unless we have a [Gaussian white noise].

#### worm plot

A worm plot, @vanBuurenFredriks01, is a [diagnostic tool] which could be applied to any standardised [residuals] of a [regression] model but more often to [z-scores] of a [distributional regression] model. A [worm plot] is a trended [QQ-plot]. Detrended to highlight departures from normality.

```{r}
resid_wp(m2)
```

#### Wald test

The [Wald test] is a large-sample hypothesis tests used to assess whether one or more model parameters equal specified values. Let an estimator $\hat{\boldsymbol{\theta}}$ with estimated covariance matrix $\widehat{\mathrm{Var}}(\hat{\boldsymbol{\theta}})$. We would like to test the [hypothesis] $H_0: \boldsymbol{\theta} = \boldsymbol{\theta}_0$. The Wald statistic is defined as $$W = (\hat{\boldsymbol{\theta}}-\boldsymbol{\theta}_0)^\top
\widehat{\mathrm{Var}}(\hat{\boldsymbol{\theta}})^{-1}
(\hat{\boldsymbol{\theta}}-\boldsymbol{\theta}_0),$$ which asymptotically follows a $\chi^2_q$ distribution, where $q$ is the [degrees of freedom] for fitting the specific [model]. In the special case of a single parameter: we can use $z = \frac{\hat{\theta}}{\mathrm{SE}(\hat{\theta})}$ which implies that $z^2 \sim \chi^2_1$. Small [p-value] of the test reject $H_0$ and conclude the the parameter(s) differ from the null value. With large p-value we have insufficient evidence against $H_0$. The [Wald test] is widely used in \[LM\]'s and [GLM]'s. It can be use [GAM]'s for testing smooths or parametric terms but it is not recommended. While the [Wald test] is simple and computationally cheap and do not required the refitting the specific [model], It relies on large-sample (asymptotic) normality so it is perform poorly with small [sample]s. Its very sensitive to specific parametrization and scaling and it is Less reliable when parameters are near their boundary [range]. Likelihood ratio test (LRT) are more reliable but required two [fit]s; one with the specific [term] in and one with the [term] out. The [score test] evaluates slope at the null hypothesis without fitting the full model.

################################################################################ 
::: {.page-break}
:::

## X

#### $X$

$X$ is used in here as a generic term for [explanatory variables], [input variables] or [independent variables] in a [regression analysis] but also is used to indicate a \[random\] variable.

################################################################################ 

::: {.page-break}
:::

## Y

#### $Y$

$Y$ is used as a generic terms for the [response], the [target], or the [y-variable] for [regression analysis] and [distributional regression]. More specifically within a [distributional regression] framework one would like to match the [range] of the [response] [vector] in the [data] with the [range] of the assumed [distribution] $D()$ for the response. This will ensure that in any [prediction] the right boundaries are observed.

#### y-variable

We refer to the [y-variable] as the variable of interest in a [regression analysis]. Other names are the [response], the [target] the **output** or the **depended variable**.

################################################################################ 

#::: {.page-break}
:::

## Z

#### z-scores

In a [distributional regression] [model] the [z-scores] are the normalised [residuals] of the [model]. If the model is an [adequate fit], we expect 95% of the [z-scores] values to fall between -2 and 2. (More precisely between -1.96 and 1.96). Therefore [z-scores] for both [training] and [test] data can be used for detection of unusual observations. The straightforward calculation of the [z-scores] is one of the great advantages of the [distributional regression] compare with \[quantile regression\], @koenker2017quantile, where the [z-scores] could be calculate but with a substantial computational cost see for example, Chapter 13 of @Stasinopoulosetal2017.

################################################################################ 
################################################################################ 
